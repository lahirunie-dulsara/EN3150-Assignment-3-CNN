{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lahirunie-dulsara/EN3150-Assignment-3-CNN/blob/Sakith/RealWaste.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHbFqHHu0YqR",
        "outputId": "7643ce5e-d225-4cf3-c3c7-28f4d8f33b26"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FQcAlzHU2Sw3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a846347-1de7-41d1-ad38-b551a0c203c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzipped to: /content/extracted_zip\n"
          ]
        }
      ],
      "source": [
        "import zipfile, os, re, shutil\n",
        "from PIL import Image\n",
        "\n",
        "zip_path = \"/content/drive/MyDrive/Real Waste.zip\"\n",
        "\n",
        "extract_path = \"/content/extracted_zip\"\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "print(\"Unzipped to:\", extract_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = \"/content/extracted_zip/realwaste-main/RealWaste\"\n",
        "for folder in os.listdir(base_dir):\n",
        "    count = len(os.listdir(os.path.join(base_dir, folder)))\n",
        "    print(f\"{folder}: {count} images\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WC34Jsja_TlT",
        "outputId": "15db47fc-3d24-4b8e-ec78-aa5063d50fa6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vegetation: 436 images\n",
            "Plastic: 921 images\n",
            "Metal: 790 images\n",
            "Paper: 500 images\n",
            "Cardboard: 461 images\n",
            "Textile Trash: 318 images\n",
            "Miscellaneous Trash: 495 images\n",
            "Glass: 420 images\n",
            "Food Organics: 411 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install split-folders"
      ],
      "metadata": {
        "id": "QfEBmPX8JGfM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7a7f3ce-7cfd-4f2a-e3c4-652b9e8f12ae"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: split-folders in /usr/local/lib/python3.12/dist-packages (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import splitfolders  # install with: pip install split-folders\n",
        "\n",
        "input_folder = \"/content/extracted_zip/realwaste-main/RealWaste\"\n",
        "output_folder = \"/content/extracted_zip/realwaste-main/realwaste_split\"\n",
        "\n",
        "splitfolders.ratio(input_folder, output=output_folder, seed=42, ratio=(.7, .15, .15))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "op1hnovlItS8",
        "outputId": "a25fbce7-46ff-4053-9f28-2a421e79c807"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 4752 files [00:03, 1235.61 files/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = \"/content/extracted_zip/realwaste-main/realwaste_split\"\n",
        "\n",
        "# Count images in each subfolder\n",
        "for split in ['train', 'val', 'test']:\n",
        "    split_path = os.path.join(base_dir, split)\n",
        "    print(f\"\\n{split.upper()} SET\")\n",
        "    total = 0\n",
        "    for cls in os.listdir(split_path):\n",
        "        cls_path = os.path.join(split_path, cls)\n",
        "        count = len(os.listdir(cls_path))\n",
        "\n",
        "        total += count\n",
        "        print(f\"  {cls}: {count} images\")\n",
        "    print(f\"Total {split}: {total} images\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lb9khb9XKCQK",
        "outputId": "e2e6155d-292f-411f-fe9d-06eb5d792504"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRAIN SET\n",
            "  Vegetation: 305 images\n",
            "  Plastic: 644 images\n",
            "  Metal: 553 images\n",
            "  Paper: 350 images\n",
            "  Cardboard: 322 images\n",
            "  Textile Trash: 222 images\n",
            "  Miscellaneous Trash: 346 images\n",
            "  Glass: 294 images\n",
            "  Food Organics: 287 images\n",
            "Total train: 3323 images\n",
            "\n",
            "VAL SET\n",
            "  Vegetation: 65 images\n",
            "  Plastic: 138 images\n",
            "  Metal: 118 images\n",
            "  Paper: 75 images\n",
            "  Cardboard: 69 images\n",
            "  Textile Trash: 47 images\n",
            "  Miscellaneous Trash: 74 images\n",
            "  Glass: 63 images\n",
            "  Food Organics: 61 images\n",
            "Total val: 710 images\n",
            "\n",
            "TEST SET\n",
            "  Vegetation: 66 images\n",
            "  Plastic: 139 images\n",
            "  Metal: 119 images\n",
            "  Paper: 75 images\n",
            "  Cardboard: 70 images\n",
            "  Textile Trash: 49 images\n",
            "  Miscellaneous Trash: 75 images\n",
            "  Glass: 63 images\n",
            "  Food Organics: 63 images\n",
            "Total test: 719 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    # transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "    # transforms.RandomHorizontalFlip(),\n",
        "    # transforms.RandomRotation(20),\n",
        "    # transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
        "])\n",
        "\n",
        "val_test_transforms = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
        "])\n",
        "\n",
        "train_dataset = datasets.ImageFolder(\"/content/extracted_zip/realwaste-main/realwaste_split/train\", transform=train_transforms)\n",
        "val_dataset   = datasets.ImageFolder(\"/content/extracted_zip/realwaste-main/realwaste_split/val\", transform=val_test_transforms)\n",
        "test_dataset  = datasets.ImageFolder(\"/content/extracted_zip/realwaste-main/realwaste_split/test\", transform=val_test_transforms)\n",
        "\n",
        "# Get number of classes and device early\n",
        "num_classes = len(train_dataset.classes)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "print(f\"Number of classes: {num_classes}\")"
      ],
      "metadata": {
        "id": "mfh7AZ8-15hW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96d5b434-8c02-44e9-9799-79250a06c3f7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Number of classes: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_counts = np.bincount(train_dataset.targets)\n",
        "print(\"Class counts:\", class_counts)\n",
        "\n",
        "class_weights_tensor = 1. / torch.tensor(class_counts, dtype=torch.float)\n",
        "\n",
        "sample_weights = [class_weights_tensor[label].item() for label in train_dataset.targets]\n",
        "\n",
        "print(\"\\nClass counts per category:\")\n",
        "for cls, count in zip(train_dataset.classes, class_counts):\n",
        "    print(f\"  {cls:15s}: {count}\")\n",
        "\n",
        "print(\"\\nClass weights (inverse of frequency):\")\n",
        "for cls, w in zip(train_dataset.classes, class_weights_tensor):\n",
        "    print(f\"  {cls:15s}: {w:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tp34UDEFO3pq",
        "outputId": "1510b15d-1340-467c-bbd2-e2ecf647a149"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class counts: [322 287 294 553 346 350 644 222 305]\n",
            "\n",
            "Class counts per category:\n",
            "  Cardboard      : 322\n",
            "  Food Organics  : 287\n",
            "  Glass          : 294\n",
            "  Metal          : 553\n",
            "  Miscellaneous Trash: 346\n",
            "  Paper          : 350\n",
            "  Plastic        : 644\n",
            "  Textile Trash  : 222\n",
            "  Vegetation     : 305\n",
            "\n",
            "Class weights (inverse of frequency):\n",
            "  Cardboard      : 0.003106\n",
            "  Food Organics  : 0.003484\n",
            "  Glass          : 0.003401\n",
            "  Metal          : 0.001808\n",
            "  Miscellaneous Trash: 0.002890\n",
            "  Paper          : 0.002857\n",
            "  Plastic        : 0.001553\n",
            "  Textile Trash  : 0.004505\n",
            "  Vegetation     : 0.003279\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "sampler = WeightedRandomSampler(\n",
        "    weights=sample_weights,\n",
        "    num_samples=len(sample_weights),\n",
        "    replacement=True\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=sampler, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "print(f\"\\nWeightedRandomSampler created successfully!\")\n",
        "print(f\"Total samples in epoch: {len(sample_weights)}\")\n",
        "print(f\"Training Batch size: {train_loader.batch_size}\")\n",
        "print(f\"Validation Batch size: {val_loader.batch_size}\")\n",
        "print(f\"Total training batches per epoch: {len(train_loader)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHJPQoRzMefy",
        "outputId": "95aefaa0-528d-4f1d-ca17-42cac110563d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "WeightedRandomSampler created successfully!\n",
            "Total samples in epoch: 3323\n",
            "Training Batch size: 32\n",
            "Validation Batch size: 32\n",
            "Total training batches per epoch: 104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import copy\n",
        "\n",
        "class WasteCNN(nn.Module):\n",
        "    def __init__(self, num_classes=9):\n",
        "        super(WasteCNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self._to_linear = None\n",
        "        self.calculate_flatten_size(256)\n",
        "\n",
        "        self.fc1 = nn.Linear(self._to_linear, 256)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "\n",
        "    def calculate_flatten_size(self, input_size):\n",
        "        with torch.no_grad():\n",
        "            x = torch.zeros(1, 3, input_size, input_size)\n",
        "            x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "            x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "            x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
        "            self._to_linear = x.view(x.size(0), -1).size(1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
        "\n",
        "        x = x.view(-1, self._to_linear)\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "print(\"WasteCNN model class defined and ready for use.\")"
      ],
      "metadata": {
        "id": "Vip9TVk2VxQy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8399729c-c71e-4532-acbc-91624bf968ce"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WasteCNN model class defined and ready for use.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_fresh_model_for_comparison(num_classes, device, base_model_path='initial_model_weights.pth'):\n",
        "    if not os.path.exists(base_model_path):\n",
        "        initial_model = WasteCNN(num_classes=num_classes).to(device)\n",
        "        torch.save(initial_model.state_dict(), base_model_path)\n",
        "        print(f\"Created and saved initial model weights to {base_model_path}\")\n",
        "        return initial_model\n",
        "    else:\n",
        "        new_model = WasteCNN(num_classes=num_classes).to(device)\n",
        "        new_model.load_state_dict(torch.load(base_model_path))\n",
        "        return new_model\n",
        "\n",
        "def run_optimizer_training_comparison(model_instance, optimizer_name, optimizer_obj, criterion_obj, scheduler_obj, num_epochs_comp, train_loader_comp, val_loader_comp, device_comp):\n",
        "    print(f\"\\nTraining with {optimizer_name} for {num_epochs_comp} epochs...\")\n",
        "\n",
        "    current_train_losses = []\n",
        "    current_train_accuracies = []\n",
        "    current_val_losses = []\n",
        "    current_val_accuracies = []\n",
        "\n",
        "    best_val_acc_run = 0.0\n",
        "    model_path_run = f'best_model_comparison_{optimizer_name.lower().replace(\" \", \"_\").replace(\"-\", \"_\")}.pth'\n",
        "\n",
        "    for epoch in range(num_epochs_comp):\n",
        "        model_instance.train()\n",
        "        running_loss = 0.0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "\n",
        "        train_loop = tqdm(train_loader_comp, desc=f\"Epoch {epoch+1}/{num_epochs_comp} ({optimizer_name} Train)\", leave=False)\n",
        "        for images, labels in train_loop:\n",
        "            images, labels = images.to(device_comp), labels.to(device_comp)\n",
        "\n",
        "            optimizer_obj.zero_grad()\n",
        "            outputs = model_instance(images)\n",
        "            loss = criterion_obj(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer_obj.step()\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "            train_loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        epoch_train_loss = running_loss / len(train_loader_comp.dataset)\n",
        "        epoch_train_accuracy = 100 * train_correct / train_total\n",
        "        current_train_losses.append(epoch_train_loss)\n",
        "        current_train_accuracies.append(epoch_train_accuracy)\n",
        "\n",
        "        if scheduler_obj:\n",
        "            scheduler_obj.step()\n",
        "\n",
        "        model_instance.eval()\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        val_running_loss = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            val_loop = tqdm(val_loader_comp, desc=f\"Epoch {epoch+1}/{num_epochs_comp} ({optimizer_name} Val)\", leave=False)\n",
        "            for images, labels in val_loop:\n",
        "                images, labels = images.to(device_comp), labels.to(device_comp)\n",
        "                outputs = model_instance(images)\n",
        "                loss = criterion_obj(outputs, labels)\n",
        "                val_running_loss += loss.item() * images.size(0)\n",
        "\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        epoch_val_loss = val_running_loss / len(val_loader_comp.dataset)\n",
        "        epoch_val_accuracy = 100 * val_correct / val_total\n",
        "        current_val_losses.append(epoch_val_loss)\n",
        "        current_val_accuracies.append(epoch_val_accuracy)\n",
        "\n",
        "        print(f\"  {optimizer_name} - Epoch [{epoch+1}/{num_epochs_comp}] \"\n",
        "              f\"Train Loss: {epoch_train_loss:.4f} | Train Acc: {epoch_train_accuracy:.2f}% | \"\n",
        "              f\"Val Loss: {epoch_val_loss:.4f} | Val Accuracy: {epoch_val_accuracy:.2f}%\")\n",
        "\n",
        "        if epoch_val_accuracy > best_val_acc_run:\n",
        "            best_val_acc_run = epoch_val_accuracy\n",
        "            torch.save(model_instance.state_dict(), model_path_run)\n",
        "\n",
        "    print(f\"--- {optimizer_name} training finished. Best Val Accuracy: {best_val_acc_run:.2f}% ---\")\n",
        "    return current_train_losses, current_train_accuracies, current_val_losses, current_val_accuracies, model_path_run"
      ],
      "metadata": {
        "id": "H4gbsIjQRzwL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"       Starting Optimizer Performance Comparison Training       \")\n",
        "print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "_ = get_fresh_model_for_comparison(num_classes, device)\n",
        "\n",
        "NUM_EPOCHS_COMP = 20\n",
        "\n",
        "criterion_comp = nn.CrossEntropyLoss()\n",
        "\n",
        "# 1. Adam Optimizer Configuration\n",
        "model_adam_comp = get_fresh_model_for_comparison(num_classes, device)\n",
        "optimizer_adam_comp = optim.Adam(model_adam_comp.parameters(), lr=0.0005, weight_decay=1e-4)\n",
        "scheduler_adam_comp = StepLR(optimizer_adam_comp, step_size=10, gamma=0.1)\n",
        "\n",
        "# 2. Standard SGD Optimizer Configuration\n",
        "model_sgd_comp = get_fresh_model_for_comparison(num_classes, device)\n",
        "optimizer_sgd_comp = optim.SGD(model_sgd_comp.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "scheduler_sgd_comp = StepLR(optimizer_sgd_comp, step_size=10, gamma=0.1)\n",
        "\n",
        "# 3. SGD with Momentum Optimizer Configuration\n",
        "model_sgd_momentum_comp = get_fresh_model_for_comparison(num_classes, device)\n",
        "optimizer_sgd_momentum_comp = optim.SGD(model_sgd_momentum_comp.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
        "scheduler_sgd_momentum_comp = StepLR(optimizer_sgd_momentum_comp, step_size=10, gamma=0.1)\n",
        "\n",
        "adam_results = run_optimizer_training_comparison(\n",
        "    model_adam_comp, \"Adam\", optimizer_adam_comp, criterion_comp, scheduler_adam_comp, NUM_EPOCHS_COMP, train_loader, val_loader, device\n",
        ")\n",
        "adam_train_losses, adam_train_accuracies, adam_val_losses, adam_val_accuracies, adam_comp_model_path = adam_results\n",
        "\n",
        "sgd_results = run_optimizer_training_comparison(\n",
        "    model_sgd_comp, \"Standard SGD\", optimizer_sgd_comp, criterion_comp, scheduler_sgd_comp, NUM_EPOCHS_COMP, train_loader, val_loader, device\n",
        ")\n",
        "sgd_train_losses, sgd_train_accuracies, sgd_val_losses, sgd_val_accuracies, sgd_comp_model_path = sgd_results\n",
        "\n",
        "sgd_momentum_results = run_optimizer_training_comparison(\n",
        "    model_sgd_momentum_comp, \"SGD with Momentum\", optimizer_sgd_momentum_comp, criterion_comp, scheduler_sgd_momentum_comp, NUM_EPOCHS_COMP, train_loader, val_loader, device\n",
        ")\n",
        "sgd_momentum_train_losses, sgd_momentum_train_accuracies, sgd_momentum_val_losses, sgd_momentum_val_accuracies, sgd_momentum_comp_model_path = sgd_momentum_results\n",
        "\n",
        "print(\"\\nOptimizer comparison training completed for all models.\")"
      ],
      "metadata": {
        "id": "zd2TbTK0pKXq",
        "outputId": "4244a99c-e825-46bb-b853-fd0d8060c75a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "       Starting Optimizer Performance Comparison Training       \n",
            "==================================================\n",
            "\n",
            "\n",
            "Training with Adam for 20 epochs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Adam - Epoch [1/20] Train Loss: 3.5337 | Train Acc: 29.07% | Val Loss: 1.8760 | Val Accuracy: 29.15%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Adam - Epoch [2/20] Train Loss: 1.8104 | Train Acc: 32.89% | Val Loss: 1.7155 | Val Accuracy: 30.56%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Adam - Epoch [3/20] Train Loss: 1.8205 | Train Acc: 31.66% | Val Loss: 1.6460 | Val Accuracy: 35.49%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Adam - Epoch [4/20] Train Loss: 1.7497 | Train Acc: 32.62% | Val Loss: 1.5523 | Val Accuracy: 40.56%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Adam - Epoch [5/20] Train Loss: 1.6326 | Train Acc: 35.96% | Val Loss: 1.4902 | Val Accuracy: 44.23%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Adam - Epoch [6/20] Train Loss: 1.5807 | Train Acc: 37.47% | Val Loss: 1.4265 | Val Accuracy: 43.52%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Adam - Epoch [7/20] Train Loss: 1.5513 | Train Acc: 39.81% | Val Loss: 1.4172 | Val Accuracy: 46.06%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Adam - Epoch [8/20] Train Loss: 1.5139 | Train Acc: 39.42% | Val Loss: 1.6590 | Val Accuracy: 38.03%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Adam - Epoch [9/20] Train Loss: 1.4953 | Train Acc: 40.26% | Val Loss: 1.3523 | Val Accuracy: 46.48%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Adam - Epoch [10/20] Train Loss: 1.4543 | Train Acc: 41.92% | Val Loss: 1.3519 | Val Accuracy: 46.62%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Adam - Epoch [11/20] Train Loss: 1.3807 | Train Acc: 44.96% | Val Loss: 1.2940 | Val Accuracy: 49.72%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Adam - Epoch [12/20] Train Loss: 1.3438 | Train Acc: 46.07% | Val Loss: 1.2616 | Val Accuracy: 50.99%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Adam - Epoch [13/20] Train Loss: 1.2974 | Train Acc: 47.61% | Val Loss: 1.2351 | Val Accuracy: 52.11%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Adam - Epoch [14/20] Train Loss: 1.3515 | Train Acc: 45.08% | Val Loss: 1.2356 | Val Accuracy: 53.24%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Adam - Epoch [15/20] Train Loss: 1.3011 | Train Acc: 46.86% | Val Loss: 1.2095 | Val Accuracy: 53.10%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Adam - Epoch [16/20] Train Loss: 1.2714 | Train Acc: 48.69% | Val Loss: 1.2327 | Val Accuracy: 51.69%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Adam - Epoch [17/20] Train Loss: 1.2616 | Train Acc: 50.02% | Val Loss: 1.2135 | Val Accuracy: 55.63%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Adam - Epoch [18/20] Train Loss: 1.3008 | Train Acc: 47.94% | Val Loss: 1.2087 | Val Accuracy: 54.93%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Adam - Epoch [19/20] Train Loss: 1.2270 | Train Acc: 50.50% | Val Loss: 1.1857 | Val Accuracy: 56.62%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Adam - Epoch [20/20] Train Loss: 1.2170 | Train Acc: 50.92% | Val Loss: 1.1777 | Val Accuracy: 55.63%\n",
            "--- Adam training finished. Best Val Accuracy: 56.62% ---\n",
            "\n",
            "Training with Standard SGD for 20 epochs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Standard SGD - Epoch [1/20] Train Loss: 2.1404 | Train Acc: 27.17% | Val Loss: 1.6580 | Val Accuracy: 39.86%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Standard SGD - Epoch [2/20] Train Loss: 1.6484 | Train Acc: 39.57% | Val Loss: 1.4911 | Val Accuracy: 42.39%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Standard SGD - Epoch [3/20] Train Loss: 1.5459 | Train Acc: 42.34% | Val Loss: 1.4128 | Val Accuracy: 48.03%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Standard SGD - Epoch [4/20] Train Loss: 1.4420 | Train Acc: 44.87% | Val Loss: 1.3262 | Val Accuracy: 50.28%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Standard SGD - Epoch [5/20] Train Loss: 1.4051 | Train Acc: 47.01% | Val Loss: 1.3142 | Val Accuracy: 53.80%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Standard SGD - Epoch [6/20] Train Loss: 1.3290 | Train Acc: 49.65% | Val Loss: 1.2985 | Val Accuracy: 49.72%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Standard SGD - Epoch [7/20] Train Loss: 1.2851 | Train Acc: 51.22% | Val Loss: 1.2115 | Val Accuracy: 54.79%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/20 (Standard SGD Train):  22%|██▏       | 23/104 [00:06<00:18,  4.41it/s, loss=1.3]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(18, 6))\n",
        "\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(range(1, NUM_EPOCHS_COMP + 1), adam_val_accuracies, marker='o', linestyle='-', label='Adam')\n",
        "plt.plot(range(1, NUM_EPOCHS_COMP + 1), sgd_val_accuracies, marker='x', linestyle='--', label='Standard SGD')\n",
        "plt.plot(range(1, NUM_EPOCHS_COMP + 1), sgd_momentum_val_accuracies, marker='^', linestyle=':', label='SGD with Momentum')\n",
        "plt.title(f\"Optimizer Comparison: Validation Accuracy ({NUM_EPOCHS_COMP} Epochs)\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(range(1, NUM_EPOCHS_COMP + 1), adam_train_losses, marker='o', linestyle='-', label='Adam')\n",
        "plt.plot(range(1, NUM_EPOCHS_COMP + 1), sgd_train_losses, marker='x', linestyle='--', label='Standard SGD')\n",
        "plt.plot(range(1, NUM_EPOCHS_COMP + 1), sgd_momentum_train_losses, marker='^', linestyle=':', label='SGD with Momentum')\n",
        "plt.title(f\"Optimizer Comparison: Training Loss ({NUM_EPOCHS_COMP} Epochs)\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(range(1, NUM_EPOCHS_COMP + 1), adam_train_accuracies, marker='o', linestyle='-', label='Adam')\n",
        "plt.plot(range(1, NUM_EPOCHS_COMP + 1), sgd_train_accuracies, marker='x', linestyle='--', label='Standard SGD')\n",
        "plt.plot(range(1, NUM_EPOCHS_COMP + 1), sgd_momentum_train_accuracies, marker='^', linestyle=':', label='SGD with Momentum')\n",
        "plt.title(f\"Optimizer Comparison: Training Accuracy ({NUM_EPOCHS_COMP} Epochs)\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nOptimizer Comparison plots generated.\")"
      ],
      "metadata": {
        "id": "Wjcw7xI3pMsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def evaluate_on_test_set_comp(model_instance, model_path, test_loader_comp, device_comp):\n",
        "    model_instance.load_state_dict(torch.load(model_path))\n",
        "    model_instance.to(device_comp)\n",
        "    model_instance.eval()\n",
        "\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        test_loop = tqdm(test_loader_comp, desc=f\"Evaluating Test Set for model from {model_path}\", leave=False)\n",
        "        for images, labels in test_loop:\n",
        "            images, labels = images.to(device_comp), labels.to(device_comp)\n",
        "            outputs = model_instance(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            test_total += labels.size(0)\n",
        "            test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    test_accuracy = 100 * test_correct / test_total\n",
        "    return test_accuracy\n",
        "\n",
        "print(\"\\n--- Evaluating Comparison Models on Test Set ---\")\n",
        "\n",
        "adam_final_test_accuracy = evaluate_on_test_set_comp(model_adam_comp, adam_comp_model_path, test_loader, device)\n",
        "print(f\"Adam (Comparison) Final Test Accuracy: {adam_final_test_accuracy:.2f}%\")\n",
        "\n",
        "sgd_final_test_accuracy = evaluate_on_test_set_comp(model_sgd_comp, sgd_comp_model_path, test_loader, device)\n",
        "print(f\"Standard SGD (Comparison) Final Test Accuracy: {sgd_final_test_accuracy:.2f}%\")\n",
        "\n",
        "sgd_momentum_final_test_accuracy = evaluate_on_test_set_comp(model_sgd_momentum_comp, sgd_momentum_comp_model_path, test_loader, device)\n",
        "print(f\"SGD with Momentum (Comparison) Final Test Accuracy: {sgd_momentum_final_test_accuracy:.2f}%\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"       Optimizer Performance Comparison Summary       \")\n",
        "print(\"=\"*50 + \"\\n\")\n",
        "print(f\"Final Test Accuracy for Adam: {adam_final_test_accuracy:.2f}%\")\n",
        "print(f\"Final Test Accuracy for Standard SGD: {sgd_final_test_accuracy:.2f}%\")\n",
        "print(f\"Final Test Accuracy for SGD with Momentum: {sgd_momentum_final_test_accuracy:.2f}%\")\n",
        "print(\"\\nOptimizer Comparison Test Evaluation Complete.\")"
      ],
      "metadata": {
        "id": "1Cp4PM9rbi4D"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}