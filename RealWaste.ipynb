{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lahirunie-dulsara/EN3150-Assignment-3-CNN/blob/Sakith/RealWaste.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive_path = \"/content/drive\"\n",
        "\n",
        "if os.path.ismount(drive_path):\n",
        "    print(\"Google Drive is already mounted. Forcing remount to refresh connection...\")\n",
        "    drive.mount(drive_path, force_remount=True)\n",
        "else:\n",
        "    print(\"Mounting Google Drive...\")\n",
        "    drive.mount(drive_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHbFqHHu0YqR",
        "outputId": "c5b93225-4a2d-485d-cdc1-8ca00a888ab3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounting Google Drive...\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQcAlzHU2Sw3"
      },
      "outputs": [],
      "source": [
        "import zipfile, os, re, shutil\n",
        "from PIL import Image\n",
        "\n",
        "zip_path = \"/content/drive/MyDrive/Real Waste.zip\"\n",
        "\n",
        "extract_path = \"/content/extracted_zip\"\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "print(\"Unzipped to:\", extract_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = \"/content/extracted_zip/realwaste-main/RealWaste\"\n",
        "for folder in os.listdir(base_dir):\n",
        "    count = len(os.listdir(os.path.join(base_dir, folder)))\n",
        "    print(f\"{folder}: {count} images\")"
      ],
      "metadata": {
        "id": "WC34Jsja_TlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install split-folders"
      ],
      "metadata": {
        "id": "QfEBmPX8JGfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import splitfolders\n",
        "\n",
        "input_folder = \"/content/extracted_zip/realwaste-main/RealWaste\"\n",
        "output_folder = \"/content/extracted_zip/realwaste-main/realwaste_split\"\n",
        "\n",
        "splitfolders.ratio(input_folder, output=output_folder, seed=42, ratio=(.7, .15, .15))"
      ],
      "metadata": {
        "id": "op1hnovlItS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = \"/content/extracted_zip/realwaste-main/realwaste_split\"\n",
        "\n",
        "for split in ['train', 'val', 'test']:\n",
        "    split_path = os.path.join(base_dir, split)\n",
        "    print(f\"\\n{split.upper()} SET\")\n",
        "    total = 0\n",
        "    for cls in os.listdir(split_path):\n",
        "        cls_path = os.path.join(split_path, cls)\n",
        "        count = len(os.listdir(cls_path))\n",
        "\n",
        "        total += count\n",
        "        print(f\"  {cls}: {count} images\")\n",
        "    print(f\"Total {split}: {total} images\")"
      ],
      "metadata": {
        "id": "lb9khb9XKCQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    # transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "    # transforms.RandomHorizontalFlip(),\n",
        "    # transforms.RandomRotation(20),\n",
        "    # transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
        "])\n",
        "\n",
        "val_test_transforms = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
        "])\n",
        "\n",
        "train_dataset = datasets.ImageFolder(\"/content/extracted_zip/realwaste-main/realwaste_split/train\", transform=train_transforms)\n",
        "val_dataset   = datasets.ImageFolder(\"/content/extracted_zip/realwaste-main/realwaste_split/val\", transform=val_test_transforms)\n",
        "test_dataset  = datasets.ImageFolder(\"/content/extracted_zip/realwaste-main/realwaste_split/test\", transform=val_test_transforms)\n",
        "\n",
        "# Get number of classes and device early\n",
        "num_classes = len(train_dataset.classes)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "print(f\"Number of classes: {num_classes}\")"
      ],
      "metadata": {
        "id": "mfh7AZ8-15hW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_counts = np.bincount(train_dataset.targets)\n",
        "print(\"Class counts:\", class_counts)\n",
        "\n",
        "class_weights_tensor = 1. / torch.tensor(class_counts, dtype=torch.float)\n",
        "\n",
        "sample_weights = [class_weights_tensor[label].item() for label in train_dataset.targets]\n",
        "\n",
        "print(\"\\nClass counts per category:\")\n",
        "for cls, count in zip(train_dataset.classes, class_counts):\n",
        "    print(f\"  {cls:15s}: {count}\")\n",
        "\n",
        "print(\"\\nClass weights (inverse of frequency):\")\n",
        "for cls, w in zip(train_dataset.classes, class_weights_tensor):\n",
        "    print(f\"  {cls:15s}: {w:.6f}\")"
      ],
      "metadata": {
        "id": "tp34UDEFO3pq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "sampler = WeightedRandomSampler(\n",
        "    weights=sample_weights,\n",
        "    num_samples=len(sample_weights),\n",
        "    replacement=True\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=sampler, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "print(f\"\\nWeightedRandomSampler created successfully!\")\n",
        "print(f\"Total samples in epoch: {len(sample_weights)}\")\n",
        "print(f\"Training Batch size: {train_loader.batch_size}\")\n",
        "print(f\"Validation Batch size: {val_loader.batch_size}\")\n",
        "print(f\"Total training batches per epoch: {len(train_loader)}\")"
      ],
      "metadata": {
        "id": "xHJPQoRzMefy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import copy\n",
        "\n",
        "class WasteCNN(nn.Module):\n",
        "    def __init__(self, num_classes=9):\n",
        "        super(WasteCNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self._to_linear = None\n",
        "        self.calculate_flatten_size(256)\n",
        "\n",
        "        self.fc1 = nn.Linear(self._to_linear, 256)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "\n",
        "    def calculate_flatten_size(self, input_size):\n",
        "        with torch.no_grad():\n",
        "            x = torch.zeros(1, 3, input_size, input_size)\n",
        "            x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "            x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "            x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
        "            self._to_linear = x.view(x.size(0), -1).size(1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
        "\n",
        "        x = x.view(-1, self._to_linear)\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "print(\"WasteCNN model class defined and ready for use.\")"
      ],
      "metadata": {
        "id": "Vip9TVk2VxQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_fresh_model_for_comparison(num_classes, device, base_model_path='initial_model_weights.pth'):\n",
        "    if not os.path.exists(base_model_path):\n",
        "        initial_model = WasteCNN(num_classes=num_classes).to(device)\n",
        "        torch.save(initial_model.state_dict(), base_model_path)\n",
        "        print(f\"Created and saved initial model weights to {base_model_path}\")\n",
        "        return initial_model\n",
        "    else:\n",
        "        new_model = WasteCNN(num_classes=num_classes).to(device)\n",
        "        new_model.load_state_dict(torch.load(base_model_path))\n",
        "        return new_model\n",
        "\n",
        "def run_optimizer_training_comparison(model_instance, optimizer_name, optimizer_obj, criterion_obj, scheduler_obj, num_epochs_comp, train_loader_comp, val_loader_comp, device_comp):\n",
        "    print(f\"\\nTraining with {optimizer_name} for {num_epochs_comp} epochs...\")\n",
        "\n",
        "    current_train_losses = []\n",
        "    current_train_accuracies = []\n",
        "    current_val_losses = []\n",
        "    current_val_accuracies = []\n",
        "\n",
        "    best_val_acc_run = 0.0\n",
        "    model_path_run = f'best_model_comparison_{optimizer_name.lower().replace(\" \", \"_\").replace(\"-\", \"_\")}.pth'\n",
        "\n",
        "    for epoch in range(num_epochs_comp):\n",
        "        model_instance.train()\n",
        "        running_loss = 0.0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "\n",
        "        train_loop = tqdm(train_loader_comp, desc=f\"Epoch {epoch+1}/{num_epochs_comp} ({optimizer_name} Train)\", leave=False)\n",
        "        for images, labels in train_loop:\n",
        "            images, labels = images.to(device_comp), labels.to(device_comp)\n",
        "\n",
        "            optimizer_obj.zero_grad()\n",
        "            outputs = model_instance(images)\n",
        "            loss = criterion_obj(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer_obj.step()\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "            train_loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        epoch_train_loss = running_loss / len(train_loader_comp.dataset)\n",
        "        epoch_train_accuracy = 100 * train_correct / train_total\n",
        "        current_train_losses.append(epoch_train_loss)\n",
        "        current_train_accuracies.append(epoch_train_accuracy)\n",
        "\n",
        "        if scheduler_obj:\n",
        "            scheduler_obj.step()\n",
        "\n",
        "        model_instance.eval()\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        val_running_loss = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            val_loop = tqdm(val_loader_comp, desc=f\"Epoch {epoch+1}/{num_epochs_comp} ({optimizer_name} Val)\", leave=False)\n",
        "            for images, labels in val_loop:\n",
        "                images, labels = images.to(device_comp), labels.to(device_comp)\n",
        "                outputs = model_instance(images)\n",
        "                loss = criterion_obj(outputs, labels)\n",
        "                val_running_loss += loss.item() * images.size(0)\n",
        "\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        epoch_val_loss = val_running_loss / len(val_loader_comp.dataset)\n",
        "        epoch_val_accuracy = 100 * val_correct / val_total\n",
        "        current_val_losses.append(epoch_val_loss)\n",
        "        current_val_accuracies.append(epoch_val_accuracy)\n",
        "\n",
        "        print(f\"  {optimizer_name} - Epoch [{epoch+1}/{num_epochs_comp}] \"\n",
        "              f\"Train Loss: {epoch_train_loss:.4f} | Train Acc: {epoch_train_accuracy:.2f}% | \"\n",
        "              f\"Val Loss: {epoch_val_loss:.4f} | Val Accuracy: {epoch_val_accuracy:.2f}%\")\n",
        "\n",
        "        if epoch_val_accuracy > best_val_acc_run:\n",
        "            best_val_acc_run = epoch_val_accuracy\n",
        "            torch.save(model_instance.state_dict(), model_path_run)\n",
        "\n",
        "    print(f\"--- {optimizer_name} training finished. Best Val Accuracy: {best_val_acc_run:.2f}% ---\")\n",
        "    return current_train_losses, current_train_accuracies, current_val_losses, current_val_accuracies, model_path_run"
      ],
      "metadata": {
        "id": "H4gbsIjQRzwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*75)\n",
        "print(\"       Starting Optimizer Performance Comparison Training       \")\n",
        "print(\"=\"*75 + \"\\n\")\n",
        "\n",
        "_ = get_fresh_model_for_comparison(num_classes, device)\n",
        "\n",
        "NUM_EPOCHS_COMP = 20\n",
        "criterion_comp = nn.CrossEntropyLoss()\n",
        "\n",
        "# 1. Adam Optimizer Configuration\n",
        "model_adam_comp = get_fresh_model_for_comparison(num_classes, device)\n",
        "optimizer_adam_comp = optim.Adam(model_adam_comp.parameters(), lr=0.00025, weight_decay=1e-4)\n",
        "scheduler_adam_comp = StepLR(optimizer_adam_comp, step_size=10, gamma=0.1)\n",
        "\n",
        "# 2. Standard SGD Optimizer Configuration\n",
        "model_sgd_comp = get_fresh_model_for_comparison(num_classes, device)\n",
        "optimizer_sgd_comp = optim.SGD(model_sgd_comp.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "scheduler_sgd_comp = StepLR(optimizer_sgd_comp, step_size=10, gamma=0.1)\n",
        "\n",
        "# 3. SGD with Momentum Optimizer Configuration\n",
        "model_sgd_momentum_comp = get_fresh_model_for_comparison(num_classes, device)\n",
        "optimizer_sgd_momentum_comp = optim.SGD(model_sgd_momentum_comp.parameters(), lr=0.005, momentum=0.9, weight_decay=1e-4)\n",
        "scheduler_sgd_momentum_comp = StepLR(optimizer_sgd_momentum_comp, step_size=10, gamma=0.1)\n",
        "\n",
        "# 4. RMSProp Optimizer Configuration\n",
        "model_rmsprop_comp = get_fresh_model_for_comparison(num_classes, device)\n",
        "optimizer_rmsprop_comp = optim.RMSprop(model_rmsprop_comp.parameters(), lr=0.0005, alpha=0.9, weight_decay=1e-4)\n",
        "scheduler_rmsprop_comp = StepLR(optimizer_rmsprop_comp, step_size=10, gamma=0.1)\n",
        "\n",
        "\n",
        "# ===================== TRAINING =====================\n",
        "adam_results = run_optimizer_training_comparison(\n",
        "    model_adam_comp, \"Adam\", optimizer_adam_comp, criterion_comp, scheduler_adam_comp,\n",
        "    NUM_EPOCHS_COMP, train_loader, val_loader, device\n",
        ")\n",
        "adam_train_losses, adam_train_accuracies, adam_val_losses, adam_val_accuracies, adam_comp_model_path = adam_results\n",
        "\n",
        "\n",
        "sgd_results = run_optimizer_training_comparison(\n",
        "    model_sgd_comp, \"Standard SGD\", optimizer_sgd_comp, criterion_comp, scheduler_sgd_comp,\n",
        "    NUM_EPOCHS_COMP, train_loader, val_loader, device\n",
        ")\n",
        "sgd_train_losses, sgd_train_accuracies, sgd_val_losses, sgd_val_accuracies, sgd_comp_model_path = sgd_results\n",
        "\n",
        "\n",
        "sgd_momentum_results = run_optimizer_training_comparison(\n",
        "    model_sgd_momentum_comp, \"SGD with Momentum\", optimizer_sgd_momentum_comp, criterion_comp, scheduler_sgd_momentum_comp,\n",
        "    NUM_EPOCHS_COMP, train_loader, val_loader, device\n",
        ")\n",
        "sgd_momentum_train_losses, sgd_momentum_train_accuracies, sgd_momentum_val_losses, sgd_momentum_val_accuracies, sgd_momentum_comp_model_path = sgd_momentum_results\n",
        "\n",
        "\n",
        "rmsprop_results = run_optimizer_training_comparison(\n",
        "    model_rmsprop_comp, \"RMSProp\", optimizer_rmsprop_comp, criterion_comp, scheduler_rmsprop_comp,\n",
        "    NUM_EPOCHS_COMP, train_loader, val_loader, device\n",
        ")\n",
        "rmsprop_train_losses, rmsprop_train_accuracies, rmsprop_val_losses, rmsprop_val_accuracies, rmsprop_comp_model_path = rmsprop_results\n",
        "\n",
        "\n",
        "print(\"\\nOptimizer comparison training completed for all models.\")\n"
      ],
      "metadata": {
        "id": "zd2TbTK0pKXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14, 10))\n",
        "\n",
        "# === Plot 1: Validation Accuracy ===\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(range(1, NUM_EPOCHS_COMP + 1), adam_val_accuracies, marker='o', linestyle='-', label='Adam')\n",
        "plt.plot(range(1, NUM_EPOCHS_COMP + 1), sgd_val_accuracies, marker='x', linestyle='--', label='Standard SGD')\n",
        "plt.plot(range(1, NUM_EPOCHS_COMP + 1), sgd_momentum_val_accuracies, marker='^', linestyle=':', label='SGD with Momentum')\n",
        "plt.plot(range(1, NUM_EPOCHS_COMP + 1), rmsprop_val_accuracies, marker='s', linestyle='-.', label='RMSProp')\n",
        "plt.title(f\"Optimizer Comparison: Validation Accuracy ({NUM_EPOCHS_COMP} Epochs)\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# === Plot 2: Training Accuracy ===\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(range(1, NUM_EPOCHS_COMP + 1), adam_train_accuracies, marker='o', linestyle='-', label='Adam')\n",
        "plt.plot(range(1, NUM_EPOCHS_COMP + 1), sgd_train_accuracies, marker='x', linestyle='--', label='Standard SGD')\n",
        "plt.plot(range(1, NUM_EPOCHS_COMP + 1), sgd_momentum_train_accuracies, marker='^', linestyle=':', label='SGD with Momentum')\n",
        "plt.plot(range(1, NUM_EPOCHS_COMP + 1), rmsprop_train_accuracies, marker='s', linestyle='-.', label='RMSProp')\n",
        "plt.title(f\"Optimizer Comparison: Training Accuracy ({NUM_EPOCHS_COMP} Epochs)\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# === Plot 3: Validation Loss ===\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.plot(range(1, NUM_EPOCHS_COMP + 1), adam_val_losses, marker='o', linestyle='-', label='Adam')\n",
        "plt.plot(range(1, NUM_EPOCHS_COMP + 1), sgd_val_losses, marker='x', linestyle='--', label='Standard SGD')\n",
        "plt.plot(range(1, NUM_EPOCHS_COMP + 1), sgd_momentum_val_losses, marker='^', linestyle=':', label='SGD with Momentum')\n",
        "plt.plot(range(1, NUM_EPOCHS_COMP + 1), rmsprop_val_losses, marker='s', linestyle='-.', label='RMSProp')\n",
        "plt.title(f\"Optimizer Comparison: Validation Loss ({NUM_EPOCHS_COMP} Epochs)\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# === Plot 4: Training Loss ===\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.plot(range(1, NUM_EPOCHS_COMP + 1), adam_train_losses, marker='o', linestyle='-', label='Adam')\n",
        "plt.plot(range(1, NUM_EPOCHS_COMP + 1), sgd_train_losses, marker='x', linestyle='--', label='Standard SGD')\n",
        "plt.plot(range(1, NUM_EPOCHS_COMP + 1), sgd_momentum_train_losses, marker='^', linestyle=':', label='SGD with Momentum')\n",
        "plt.plot(range(1, NUM_EPOCHS_COMP + 1), rmsprop_train_losses, marker='s', linestyle='-.', label='RMSProp')\n",
        "plt.title(f\"Optimizer Comparison: Training Loss ({NUM_EPOCHS_COMP} Epochs)\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nOptimizer Comparison plots generated.\")\n"
      ],
      "metadata": {
        "id": "Wjcw7xI3pMsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_on_test_set_comp(model_instance, model_path, test_loader_comp, device_comp):\n",
        "    model_instance.load_state_dict(torch.load(model_path))\n",
        "    model_instance.to(device_comp)\n",
        "    model_instance.eval()\n",
        "\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        test_loop = tqdm(test_loader_comp, desc=f\"Evaluating Test Set for model from {model_path}\", leave=False)\n",
        "        for images, labels in test_loop:\n",
        "            images, labels = images.to(device_comp), labels.to(device_comp)\n",
        "            outputs = model_instance(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            test_total += labels.size(0)\n",
        "            test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    test_accuracy = 100 * test_correct / test_total\n",
        "    return test_accuracy\n",
        "\n",
        "\n",
        "print(\"\\n--- Evaluating Comparison Models on Test Set ---\")\n",
        "\n",
        "adam_final_test_accuracy = evaluate_on_test_set_comp(model_adam_comp, adam_comp_model_path, test_loader, device)\n",
        "sgd_final_test_accuracy = evaluate_on_test_set_comp(model_sgd_comp, sgd_comp_model_path, test_loader, device)\n",
        "sgd_momentum_final_test_accuracy = evaluate_on_test_set_comp(model_sgd_momentum_comp, sgd_momentum_comp_model_path, test_loader, device)\n",
        "rmsprop_final_test_accuracy = evaluate_on_test_set_comp(model_rmsprop_comp, rmsprop_comp_model_path, test_loader, device)\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*75)\n",
        "print(\"       Optimizer Performance Comparison Summary       \")\n",
        "print(\"=\"*75 + \"\\n\")\n",
        "print(f\"Final Test Accuracy for Adam: {adam_final_test_accuracy:.2f}%\")\n",
        "print(f\"Final Test Accuracy for Standard SGD: {sgd_final_test_accuracy:.2f}%\")\n",
        "print(f\"Final Test Accuracy for SGD with Momentum: {sgd_momentum_final_test_accuracy:.2f}%\")\n",
        "print(f\"Final Test Accuracy for RMSProp: {rmsprop_final_test_accuracy:.2f}%\")\n",
        "\n",
        "print(\"\\nOptimizer Comparison Test Evaluation Complete.\")\n"
      ],
      "metadata": {
        "id": "1Cp4PM9rbi4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "def plot_confusion_matrix(model, model_path, test_loader, device, optimizer_name, class_names=None):\n",
        "\n",
        "    # Load model weights\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    acc = 100 * np.trace(cm) / np.sum(cm)\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title(f\"Confusion Matrix: {optimizer_name} (Accuracy: {acc:.2f}%)\")\n",
        "    plt.xlabel(\"Predicted Labels\")\n",
        "    plt.ylabel(\"True Labels\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# === Example: Generate confusion matrix for each optimizer ===\n",
        "print(\"\\n--- Generating Confusion Matrices for All Optimizers ---\")\n",
        "\n",
        "class_names = test_loader.dataset.classes if hasattr(test_loader.dataset, \"classes\") else None\n",
        "\n",
        "plot_confusion_matrix(model_adam_comp, adam_comp_model_path, test_loader, device, \"Adam\", class_names)\n",
        "plot_confusion_matrix(model_sgd_comp, sgd_comp_model_path, test_loader, device, \"Standard SGD\", class_names)\n",
        "plot_confusion_matrix(model_sgd_momentum_comp, sgd_momentum_comp_model_path, test_loader, device, \"SGD with Momentum\", class_names)\n",
        "plot_confusion_matrix(model_rmsprop_comp, rmsprop_comp_model_path, test_loader, device, \"RMSProp\", class_names)\n",
        "\n",
        "print(\"\\n✅ Confusion matrices generated for all optimizer models.\")\n"
      ],
      "metadata": {
        "id": "9ZHexnCrJG_m"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}