{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 7432092,
          "sourceType": "datasetVersion",
          "datasetId": 4324996
        },
        {
          "sourceId": 10616273,
          "sourceType": "datasetVersion",
          "datasetId": 6572802
        },
        {
          "sourceId": 10625764,
          "sourceType": "datasetVersion",
          "datasetId": 6579000
        },
        {
          "sourceId": 10626852,
          "sourceType": "datasetVersion",
          "datasetId": 6579642
        },
        {
          "sourceId": 10642600,
          "sourceType": "datasetVersion",
          "datasetId": 6589583
        },
        {
          "sourceId": 10649574,
          "sourceType": "datasetVersion",
          "datasetId": 6594225
        },
        {
          "sourceId": 225046,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 191963,
          "modelId": 213920
        },
        {
          "sourceId": 247757,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": true,
          "modelInstanceId": 211764,
          "modelId": 233451
        }
      ],
      "dockerImageVersionId": 30822,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lahirunie-dulsara/EN3150-Assignment-3-CNN/blob/Aazir/realwaste_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-03T14:47:14.525538Z",
          "iopub.execute_input": "2025-02-03T14:47:14.525954Z",
          "iopub.status.idle": "2025-02-03T14:47:19.172719Z",
          "shell.execute_reply.started": "2025-02-03T14:47:14.525918Z",
          "shell.execute_reply": "2025-02-03T14:47:19.172033Z"
        },
        "id": "MZoPEPYVJQwY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "AtNKSG8uODOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-03T14:47:19.173859Z",
          "iopub.execute_input": "2025-02-03T14:47:19.174269Z",
          "iopub.status.idle": "2025-02-03T14:47:19.241682Z",
          "shell.execute_reply.started": "2025-02-03T14:47:19.174239Z",
          "shell.execute_reply": "2025-02-03T14:47:19.240961Z"
        },
        "id": "JNUl-v37JQwc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile, os, re, shutil\n",
        "from PIL import Image\n",
        "\n",
        "zip_path = \"/content/drive/MyDrive/Pattern Recognition/realwaste.zip\"\n",
        "\n",
        "extract_path = \"/content\"\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "print(\"Unzipped to:\", extract_path)\n"
      ],
      "metadata": {
        "id": "SOxPnB17OV_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = \"/content/realwaste-main/RealWaste\"\n",
        "for folder in os.listdir(base_dir):\n",
        "    count = len(os.listdir(os.path.join(base_dir, folder)))\n",
        "    print(f\"{folder}: {count} images\")"
      ],
      "metadata": {
        "id": "eurMme0qObLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "# Configuration\n",
        "BATCH_SIZE = 64\n",
        "IMG_SIZE = (224, 224)\n",
        "TEST_SPLIT = 0.15\n",
        "VAL_SPLIT = 0.15\n",
        "RANDOM_SEED = 42\n",
        "DATA_DIR = \"/content/realwaste-main/RealWaste\"\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(RANDOM_SEED)\n",
        "\n",
        "class RealWasteDataset(Dataset):\n",
        "    def __init__(self, root_dir=None, data=[], labels=[], size=None, transforms=[], transform=None, print_info=True):\n",
        "        self.root_dir = root_dir\n",
        "        self.transforms = transforms\n",
        "        self.transform = transform\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.image_sizes = {} if size is None else {size}\n",
        "\n",
        "        # Class mapping\n",
        "        self.classes = {\n",
        "            0: 'Cardboard', 1: 'Food Organics', 2: 'Glass', 3: 'Metal',\n",
        "            4: 'Miscellaneous Trash', 5: 'Paper', 6: 'Plastic', 7: 'Textile Trash', 8: 'Vegetation'\n",
        "        }\n",
        "\n",
        "        start = time.time()\n",
        "\n",
        "        if root_dir is not None:\n",
        "            for label, label_name in self.classes.items():\n",
        "                class_dir = os.path.join(self.root_dir, label_name)\n",
        "                if not os.path.exists(class_dir):\n",
        "                    continue\n",
        "                for img_name in os.listdir(class_dir):\n",
        "                    img_path = os.path.join(class_dir, img_name)\n",
        "\n",
        "                    try:\n",
        "                        with Image.open(img_path) as img:\n",
        "                            img.verify()\n",
        "                            img_size = img.size\n",
        "                            self.image_sizes[img_size] = self.image_sizes.get(img_size, 0) + 1\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error loading image {img_path}: {e}\")\n",
        "                        continue\n",
        "\n",
        "                    self.data.append(img_path)\n",
        "                    self.labels.append(label)\n",
        "\n",
        "        end = time.time()\n",
        "\n",
        "        if print_info:\n",
        "            self.print_info(round(end - start, 2))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.data[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transforms:\n",
        "            image = self.transforms[idx](image)\n",
        "        elif self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "    def to_dataframe(self):\n",
        "        return pd.DataFrame({\n",
        "            'image_path': self.data,\n",
        "            'label': self.labels,\n",
        "            'transformation': [self.transform for _ in range(len(self.labels))]\n",
        "        })\n",
        "\n",
        "    def print_info(self, elapsed):\n",
        "        print(\"----------Dataset Summary----------\")\n",
        "        print(f\"Total images: {len(self.data)}\")\n",
        "        print(f\"Number of classes: {len(self.classes)}\")\n",
        "        print(\"Images per class:\")\n",
        "\n",
        "        class_counts = {label_name: 0 for label_name in self.classes.values()}\n",
        "        for label in self.labels:\n",
        "            class_name = self.classes[label]\n",
        "            class_counts[class_name] += 1\n",
        "\n",
        "        for class_name, count in class_counts.items():\n",
        "            print(f\"  {class_name}: {count} images\")\n",
        "\n",
        "        print(\"\\nUnique image sizes:\")\n",
        "        for size, count in self.image_sizes.items():\n",
        "            print(f\"  {size}: {count} images\")\n",
        "        print(f\"\\nLoaded in {elapsed} seconds!\")\n",
        "\n",
        "transform = transforms.Compose([\n",
        "        transforms.Resize(IMG_SIZE),\n",
        "        transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "full_dataset = RealWasteDataset(DATA_DIR, transform=transform)\n",
        "\n",
        "# Visualize class distribution\n",
        "def plot_class_distribution_from_dataframe(dataframe, label_to_class, title=\"Image Distribution per Class\", color='skyblue'):\n",
        "    label_counts = Counter(dataframe['label'])\n",
        "    sorted_labels = sorted(label_counts.items())\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    bars = plt.bar([label_to_class[label] for label, _ in sorted_labels], [count for _, count in sorted_labels], color=color)\n",
        "\n",
        "    for bar in bars:\n",
        "        yval = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width() / 2, yval + 2, str(yval), ha='center', fontsize=10, color='black')\n",
        "\n",
        "    plt.title(title, fontsize=16)\n",
        "    plt.xlabel(\"Classes\", fontsize=12)\n",
        "    plt.ylabel(\"Number of Images\", fontsize=12)\n",
        "    plt.xticks(rotation=45, fontsize=10)\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_class_distribution_from_dataframe(full_dataset.to_dataframe(), full_dataset.classes)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-03T17:34:23.937597Z",
          "iopub.execute_input": "2025-02-03T17:34:23.937883Z",
          "iopub.status.idle": "2025-02-03T17:34:30.349433Z",
          "shell.execute_reply.started": "2025-02-03T17:34:23.937860Z",
          "shell.execute_reply": "2025-02-03T17:34:30.348372Z"
        },
        "id": "XQsjNp3GJQwh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Stratified Split\n",
        "def train_val_test_split(full_dataframe, test_size, val_size, random_seed=RANDOM_SEED):\n",
        "    stratified_split = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=random_seed)\n",
        "    for train_val_idx, test_idx in stratified_split.split(full_dataframe, full_dataframe['label']):\n",
        "        train_val_df = full_dataframe.iloc[train_val_idx]\n",
        "        test_df = full_dataframe.iloc[test_idx]\n",
        "\n",
        "    val_adjusted_size = val_size / (1 - test_size)\n",
        "    stratified_split = StratifiedShuffleSplit(n_splits=1, test_size=val_adjusted_size, random_state=random_seed)\n",
        "    for train_idx, val_idx in stratified_split.split(train_val_df, train_val_df['label']):\n",
        "        train_df = train_val_df.iloc[train_idx]\n",
        "        val_df = train_val_df.iloc[val_idx]\n",
        "\n",
        "    return train_df, val_df, test_df\n",
        "\n",
        "train_df, val_df, test_df = train_val_test_split(full_dataset.to_dataframe(), test_size=TEST_SPLIT, val_size=VAL_SPLIT)\n",
        "\n",
        "# Visualizing Augmented Dataset\n",
        "def augment_train(train_df, duplication_factor):\n",
        "    transform_augment = transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.RandomRotation(degrees=45),\n",
        "        transforms.RandomResizedCrop(size=IMG_SIZE[0], scale=(0.6, 0.9)),\n",
        "        transforms.Resize(IMG_SIZE),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    augmented_rows = []\n",
        "    for _, row in tqdm(train_df.iterrows(), total=len(train_df), desc=\"Augmenting Images\"):\n",
        "        img_path, label = row['image_path'], row['label']\n",
        "        for _ in range(duplication_factor):\n",
        "            augmented_rows.append({\n",
        "                \"image_path\": img_path,\n",
        "                \"label\": label,\n",
        "                \"transformation\": transform_augment\n",
        "            })\n",
        "\n",
        "    augmented_df = pd.DataFrame(augmented_rows)\n",
        "    combined_df = pd.concat([train_df, augmented_df], ignore_index=True)\n",
        "    return combined_df\n",
        "\n",
        "train_df_augmented = augment_train(train_df, duplication_factor=3)\n",
        "\n",
        "plot_class_distribution_from_dataframe(train_df_augmented, full_dataset.classes)\n",
        "\n",
        "# Visualizing Training Images by Class\n",
        "def plot_training_images_by_class(train_df_augmented, class_names, ncols=5, title=\"Examples of Images by Class\"):\n",
        "    sampled_images = defaultdict(list)\n",
        "    for label in train_df_augmented['label'].unique():\n",
        "        class_df = train_df_augmented[train_df_augmented['label'] == label]\n",
        "        sampled_df = class_df.sample(min(len(class_df), ncols), random_state=RANDOM_SEED)\n",
        "        for _, row in sampled_df.iterrows():\n",
        "            sampled_images[label].append(row)\n",
        "\n",
        "    classes = sorted(sampled_images.keys())\n",
        "    nrows = len(classes)\n",
        "    fig, axs = plt.subplots(nrows, ncols + 1, figsize=(ncols * 2.5, nrows * 2))\n",
        "    fig.suptitle(title, fontsize=16)\n",
        "\n",
        "    for i, label in enumerate(classes):\n",
        "        axs[i, 0].imshow(Image.open(sampled_images[label][0]['image_path']))\n",
        "        axs[i, 0].set_title(class_names[label], fontsize=12)\n",
        "        axs[i, 0].axis('off')\n",
        "\n",
        "        for j in range(ncols):\n",
        "            img_path = sampled_images[label][j]['image_path']\n",
        "            axs[i, j+1].imshow(Image.open(img_path))\n",
        "            axs[i, j+1].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_training_images_by_class(train_df_augmented, full_dataset.classes)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-03T17:34:33.686174Z",
          "iopub.execute_input": "2025-02-03T17:34:33.686460Z",
          "iopub.status.idle": "2025-02-03T17:34:38.070746Z",
          "shell.execute_reply.started": "2025-02-03T17:34:33.686436Z",
          "shell.execute_reply": "2025-02-03T17:34:38.069582Z"
        },
        "id": "tfwMS3wwJQwl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "class RealWasteDataset(Dataset):\n",
        "    def __init__(self, data, labels, transforms=None, print_info=True):\n",
        "        self.data = data  # List of image paths\n",
        "        self.labels = labels  # List of labels (numeric or one-hot encoded)\n",
        "        self.transforms = transforms  # List of transformations\n",
        "        self.print_info = print_info  # Whether to print dataset info\n",
        "\n",
        "        # Print dataset info if specified\n",
        "        if self.print_info:\n",
        "            print(f\"Dataset contains {len(data)} images.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Load the image\n",
        "        img_path = self.data[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        img = Image.open(img_path)\n",
        "\n",
        "        # Apply transformations (if any)\n",
        "        if self.transforms:\n",
        "            img = self.transforms[idx](img)\n",
        "\n",
        "        return img, label\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-03T17:35:43.419379Z",
          "iopub.execute_input": "2025-02-03T17:35:43.419680Z",
          "iopub.status.idle": "2025-02-03T17:35:43.425012Z",
          "shell.execute_reply.started": "2025-02-03T17:35:43.419658Z",
          "shell.execute_reply": "2025-02-03T17:35:43.424214Z"
        },
        "id": "_nYiarx7JQwm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Constants\n",
        "BATCH_SIZE = 32  # Example batch size\n",
        "\n",
        "# Assuming you have the augmented DataFrames loaded as train_df_augmented, val_df, test_df\n",
        "# # Replace this with your actual DataFrame loading method\n",
        "\n",
        "# # Example data for the DataLoader\n",
        "# train_df_augmented = pd.read_csv('/path/to/your/train_df_augmented.csv')\n",
        "# val_df = pd.read_csv('/path/to/your/val_df.csv')\n",
        "# test_df = pd.read_csv('/path/to/your/test_df.csv')\n",
        "\n",
        "# Create Datasets\n",
        "train_dataset = RealWasteDataset(\n",
        "    data=train_df_augmented['image_path'].to_list(),\n",
        "    labels=train_df_augmented['label'].to_list(),\n",
        "    transforms=train_df_augmented['transformation'].to_list(),\n",
        "    print_info=False\n",
        ")\n",
        "\n",
        "val_dataset = RealWasteDataset(\n",
        "    data=val_df['image_path'].to_list(),\n",
        "    labels=val_df['label'].to_list(),\n",
        "    transforms=val_df['transformation'].to_list(),\n",
        "    print_info=False\n",
        ")\n",
        "\n",
        "test_dataset = RealWasteDataset(\n",
        "    data=test_df['image_path'].to_list(),\n",
        "    labels=test_df['label'].to_list(),\n",
        "    transforms=test_df['transformation'].to_list(),\n",
        "    print_info=False\n",
        ")\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Print dataset information\n",
        "print(\"Train\", end='\\n\\t')\n",
        "print(f\"Batches: {len(train_loader)}\", end='\\n\\t')\n",
        "print(f\"Images: {len(train_loader.dataset)}\")\n",
        "print(\"Validation\", end='\\n\\t')\n",
        "print(f\"Batches: {len(val_loader)}\", end='\\n\\t')\n",
        "print(f\"Images: {len(val_loader.dataset)}\")\n",
        "print(\"Test\", end='\\n\\t')\n",
        "print(f\"Batches: {len(test_loader)}\", end='\\n\\t')\n",
        "print(f\"Images: {len(test_loader.dataset)}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-03T19:19:05.932884Z",
          "iopub.execute_input": "2025-02-03T19:19:05.933193Z",
          "iopub.status.idle": "2025-02-03T19:19:05.942506Z",
          "shell.execute_reply.started": "2025-02-03T19:19:05.933156Z",
          "shell.execute_reply": "2025-02-03T19:19:05.941656Z"
        },
        "id": "TXrEqAYBJQwn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Create the class weights\n",
        "class_counts = np.bincount(train_dataset.labels)\n",
        "class_weights = 1.0 / class_counts\n",
        "class_weights = class_weights / class_weights.sum() * len(class_counts)\n",
        "num_classes = len(full_dataset.classes)\n",
        "\n",
        "# Get the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Update the training results dataframe\n",
        "def update_training_results_csv(model_name, optimizer, lr, weight_decay, train_losses, val_losses, train_accuracies, val_accuracies):\n",
        "\n",
        "    csv_path = 'training_results.csv'\n",
        "\n",
        "    # Controlla se il file CSV esiste\n",
        "    if os.path.exists(csv_path):\n",
        "        df = pd.read_csv(csv_path)\n",
        "    else:\n",
        "        # Se non esiste, crea un DataFrame vuoto con le colonne necessarie\n",
        "        df = pd.DataFrame(columns=[\"model_name\",\n",
        "                                   \"epoch\",\n",
        "                                   \"optimizer\",\n",
        "                                   \"learning_rate\",\n",
        "                                   \"weight_decay\",\n",
        "                                   \"train_loss\",\n",
        "                                   \"val_loss\",\n",
        "                                   \"train_accuracy\",\n",
        "                                   \"val_accuracy\"\n",
        "                                  ]\n",
        "                         )\n",
        "\n",
        "    # Rimuovi eventuali vecchie entry per il modello\n",
        "    df = df[df['model_name'] != model_name]\n",
        "\n",
        "    # Crea un nuovo DataFrame con i risultati attuali\n",
        "    new_entries = {\n",
        "        \"model_name\": [model_name] * len(train_losses),\n",
        "        \"epoch\": list(range(1, len(train_losses) + 1)),\n",
        "        \"optimizer\": [optimizer] * len(train_losses),\n",
        "        \"learning_rate\": [lr] * len(train_losses),\n",
        "        \"weight_decay\": [weight_decay] * len(train_losses),\n",
        "        \"train_loss\": train_losses,\n",
        "        \"val_loss\": val_losses,\n",
        "        \"train_accuracy\": train_accuracies,\n",
        "        \"val_accuracy\": val_accuracies\n",
        "    }\n",
        "\n",
        "    new_df = pd.DataFrame(new_entries)\n",
        "\n",
        "    # Concatenare i nuovi dati con quelli esistenti\n",
        "    df = pd.concat([df, new_df], ignore_index=True)\n",
        "\n",
        "    # Salva il DataFrame aggiornato nel file CSV\n",
        "    df.to_csv(csv_path, index=False)\n",
        "\n",
        "    print(f\"Dati di training per '{model_name}' aggiornati in '{csv_path}'\")\n",
        "\n",
        "# Function to train the model with a progress bar\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
        "    train_losses, val_losses = [], []\n",
        "    train_accuracies, val_accuracies = [], []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct_train = 0\n",
        "        total_train = 0\n",
        "\n",
        "        # Progress bar for training\n",
        "        with tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{num_epochs}\", unit=\"batch\") as tepoch:\n",
        "            for images, labels in tepoch:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                # Zero the gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward pass through the model\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # Backpropagation\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                running_loss += loss.item()\n",
        "\n",
        "                # Calculate accuracy\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total_train += labels.size(0)\n",
        "                correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "                # Update the progress bar\n",
        "                tepoch.set_postfix(loss=running_loss / len(tepoch), accuracy=100 * correct_train / total_train)\n",
        "\n",
        "        train_losses.append(running_loss / len(train_loader))\n",
        "        train_accuracies.append(100 * correct_train / total_train)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        correct_val = 0\n",
        "        total_val = 0\n",
        "\n",
        "        # Progress bar for validation\n",
        "        with tqdm(val_loader, desc=f\"Validation Epoch {epoch+1}/{num_epochs}\", unit=\"batch\") as vepoch:\n",
        "            with torch.no_grad():\n",
        "                for images, labels in vepoch:\n",
        "                    images, labels = images.to(device), labels.to(device)\n",
        "                    outputs = model(images)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    val_loss += loss.item()\n",
        "\n",
        "                    # Calculate accuracy\n",
        "                    _, predicted = torch.max(outputs, 1)\n",
        "                    total_val += labels.size(0)\n",
        "                    correct_val += (predicted == labels).sum().item()\n",
        "\n",
        "                    # Update the progress bar\n",
        "                    vepoch.set_postfix(loss=val_loss / len(vepoch), accuracy=100 * correct_val / total_val)\n",
        "\n",
        "        val_losses.append(val_loss / len(val_loader))\n",
        "        val_accuracies.append(100 * correct_val / total_val)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
        "              f\"Train Loss: {train_losses[-1]:.4f}, Train Accuracy: {train_accuracies[-1]:.2f}%, \"\n",
        "              f\"Val Loss: {val_losses[-1]:.4f}, Val Accuracy: {val_accuracies[-1]:.2f}%\")\n",
        "\n",
        "    return train_losses, val_losses, train_accuracies, val_accuracies\n",
        "\n",
        "# Useful plot function\n",
        "def plot_training_validation_metrics(train_losses, val_losses, train_accuracies, val_accuracies):\n",
        "    \"\"\"\n",
        "    Function to plot the graph of losses and accuracies during training and validation.\n",
        "\n",
        "    Args:\n",
        "        train_losses (list): List containing loss values during training.\n",
        "        val_losses (list): List containing loss values during validation.\n",
        "        train_accuracies (list): List containing accuracies during training.\n",
        "        val_accuracies (list): List containing accuracies during validation.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Loss plot\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_losses, label='Train Loss')\n",
        "    plt.plot(val_losses, label='Validation Loss')\n",
        "    plt.title('Loss per Epoch')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Accuracy plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(train_accuracies, label='Train Accuracy')\n",
        "    plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "    plt.title('Accuracy per Epoch')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-03T17:37:46.016882Z",
          "iopub.execute_input": "2025-02-03T17:37:46.017197Z",
          "iopub.status.idle": "2025-02-03T17:37:46.033530Z",
          "shell.execute_reply.started": "2025-02-03T17:37:46.017168Z",
          "shell.execute_reply": "2025-02-03T17:37:46.032683Z"
        },
        "id": "x3c17eERJQwn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, num_classes=9):\n",
        "        super(CNNModel, self).__init__()\n",
        "\n",
        "        # Blocco convoluzionale base\n",
        "        self.conv_block1 = self._create_conv_block(3, 64)  # 64 filtri\n",
        "        self.conv_block2 = self._create_conv_block(64, 128)  # 128 filtri\n",
        "        self.conv_block3 = self._create_conv_block(128, 256)  # 256 filtri\n",
        "        self.conv_block4 = self._create_conv_block(256, 512)  # 512 filtri\n",
        "        self.conv_block5 = self._create_conv_block(512, 512)  # 512 filtri aggiuntivi\n",
        "\n",
        "        # Global Average Pooling\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        # Strati completamente connessi\n",
        "        self.fc1 = nn.Linear(512, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def _create_conv_block(self, in_channels, out_channels):\n",
        "        \"\"\"Crea un blocco convoluzionale standard.\"\"\"\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_block1(x)\n",
        "        x = self.conv_block2(x)\n",
        "        x = self.conv_block3(x)\n",
        "        x = self.conv_block4(x)\n",
        "        x = self.conv_block5(x)\n",
        "\n",
        "        # Global Average Pooling\n",
        "        x = self.global_avg_pool(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "\n",
        "        # Strati densi\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "# Istanza del modello\n",
        "model = CNNModel(num_classes=9)\n",
        "\n",
        "model_name = \"Custom CNN\"\n",
        "\n",
        "# Configurazione del dispositivo\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Conversione dei pesi al dispositivo\n",
        "weights = torch.tensor(class_weights.copy(), dtype=torch.float32).to(device)  # Personalizza i pesi\n",
        "criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "# Modello sul dispositivo\n",
        "model = model.to(device)\n",
        "\n",
        "# Ottimizzatore\n",
        "learning_rate = 1e-5\n",
        "weight_decay = 1e-2\n",
        "optimizer = optim.Adam(\n",
        "    filter(lambda p: p.requires_grad, model.parameters()),\n",
        "    lr=learning_rate,\n",
        "    weight_decay=weight_decay\n",
        ")\n",
        "\n",
        "# Scheduler del learning rate\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "\n",
        "# Numero di epoche\n",
        "num_epochs = 15\n",
        "\n",
        "# Training del modello\n",
        "train_losses, val_losses, train_accuracies, val_accuracies = train_model(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    num_epochs=num_epochs\n",
        ")\n",
        "\n",
        "# Save the model\n",
        "model_save_path = f\"/kaggle/working/trained_{model_name}_model.pth\"\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "print(f\"Model saved to {model_save_path}\")\n",
        "\n",
        "# Update metrics dataset\n",
        "update_training_results_csv(model_name, \"adam\", learning_rate, weight_decay, train_losses, val_losses, train_accuracies, val_accuracies)\n",
        "\n",
        "# Plot delle metriche di training e validazione\n",
        "plot_training_validation_metrics(\n",
        "    train_losses=train_losses,\n",
        "    val_losses=val_losses,\n",
        "    train_accuracies=train_accuracies,\n",
        "    val_accuracies=val_accuracies\n",
        ")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-03T17:38:12.219585Z",
          "iopub.execute_input": "2025-02-03T17:38:12.219901Z",
          "iopub.status.idle": "2025-02-03T19:01:47.520901Z",
          "shell.execute_reply.started": "2025-02-03T17:38:12.219872Z",
          "shell.execute_reply": "2025-02-03T19:01:47.520004Z"
        },
        "id": "O-w9CQXwJQwq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model_save_path = f\"/content/trained_{model_name}_model.pth\"\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "print(f\"Model saved to {model_save_path}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-03T19:15:08.777556Z",
          "iopub.execute_input": "2025-02-03T19:15:08.777883Z",
          "iopub.status.idle": "2025-02-03T19:15:08.875795Z",
          "shell.execute_reply.started": "2025-02-03T19:15:08.777856Z",
          "shell.execute_reply": "2025-02-03T19:15:08.875000Z"
        },
        "id": "gL6mDTAVJQwr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Set the path to the directory containing the models\n",
        "models_path = \"/content/\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# List of class names\n",
        "class_names = [\n",
        "    'Cardboard',\n",
        "    'Food Organics',\n",
        "    'Glass',\n",
        "    'Metal',\n",
        "    'Miscellaneous Trash',\n",
        "    'Paper',\n",
        "    'Plastic',\n",
        "    'Textile Trash',\n",
        "    'Vegetation'\n",
        "]\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, num_classes=9):\n",
        "        super(CNNModel, self).__init__()\n",
        "\n",
        "        # Blocco convoluzionale base\n",
        "        self.conv_block1 = self._create_conv_block(3, 64)  # 64 filtri\n",
        "        self.conv_block2 = self._create_conv_block(64, 128)  # 128 filtri\n",
        "        self.conv_block3 = self._create_conv_block(128, 256)  # 256 filtri\n",
        "        self.conv_block4 = self._create_conv_block(256, 512)  # 512 filtri\n",
        "        self.conv_block5 = self._create_conv_block(512, 512)  # 512 filtri aggiuntivi\n",
        "\n",
        "        # Global Average Pooling\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        # Strati completamente connessi\n",
        "        self.fc1 = nn.Linear(512, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def _create_conv_block(self, in_channels, out_channels):\n",
        "        \"\"\"Crea un blocco convoluzionale standard.\"\"\"\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_block1(x)\n",
        "        x = self.conv_block2(x)\n",
        "        x = self.conv_block3(x)\n",
        "        x = self.conv_block4(x)\n",
        "        x = self.conv_block5(x)\n",
        "\n",
        "        # Global Average Pooling\n",
        "        x = self.global_avg_pool(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "\n",
        "        # Strati densi\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "def load_custom_cnn_model(model_path, num_classes):\n",
        "    \"\"\"Load the custom CNN model.\"\"\"\n",
        "    model = CNNModel(num_classes=num_classes)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "def evaluate_custom_cnn_models(models_path, test_loader, num_classes):\n",
        "    \"\"\"Evaluate the custom CNN model and store predictions and labels.\"\"\"\n",
        "    model_files = [f for f in os.listdir(models_path) if f.endswith(\"model.pth\")]\n",
        "    results = {}\n",
        "    for model_file in model_files:\n",
        "        model_path = os.path.join(models_path, model_file)\n",
        "        print(f\"Evaluating custom CNN model: {model_file}\")\n",
        "        model = load_custom_cnn_model(model_path, num_classes)\n",
        "        all_preds, all_labels = [], []\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                all_preds.append(predicted.cpu().numpy())\n",
        "                all_labels.append(labels.cpu().numpy())\n",
        "        results[model_file] = {\n",
        "            \"preds\": np.concatenate(all_preds),\n",
        "            \"labels\": np.concatenate(all_labels)\n",
        "        }\n",
        "    return results\n",
        "\n",
        "def plot_confusion_matrices(results):\n",
        "    \"\"\"Plot normalized confusion matrices (percentages) for all models with a maximum of three matrices per row.\"\"\"\n",
        "    num_models = len(results)\n",
        "    cols = 3  # Max 3 confusion matrices per row\n",
        "    rows = -(-num_models // cols)  # Round up division to calculate number of rows\n",
        "\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(8 * cols, 8 * rows), dpi=150)\n",
        "    axes = axes.flatten()  # Flatten axes array for easier indexing\n",
        "\n",
        "    for i, (model_file, data) in enumerate(results.items()):\n",
        "        # Compute confusion matrix and normalize it by row\n",
        "        cm = confusion_matrix(data[\"labels\"], data[\"preds\"], normalize='true')\n",
        "        cm_percentage = cm * 100  # Convert to percentage\n",
        "\n",
        "        # Plot confusion matrix with percentages rounded to 1 decimal place\n",
        "        sns.heatmap(cm_percentage, annot=True, fmt='.1f', cmap='Blues',\n",
        "                    xticklabels=class_names, yticklabels=class_names, ax=axes[i])\n",
        "        axes[i].set_title(f\"Confusion Matrix (Normalized)\\n{model_file}\", fontsize=12)\n",
        "        axes[i].set_xlabel(\"Predicted\")\n",
        "        axes[i].set_ylabel(\"True\")\n",
        "        axes[i].set_aspect('equal')  # Maintain aspect ratio\n",
        "\n",
        "    # Remove unused axes if number of models is less than the grid size\n",
        "    for j in range(i + 1, len(axes)):\n",
        "        fig.delaxes(axes[j])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"confusion_matrices.png\", dpi=300, bbox_inches=\"tight\", format=\"png\")\n",
        "    plt.show()\n",
        "\n",
        "def plot_classification_reports(results):\n",
        "    \"\"\"Plot classification reports for all models.\"\"\"\n",
        "    for model_file, data in results.items():\n",
        "        report = classification_report(data[\"labels\"], data[\"preds\"], target_names=class_names)\n",
        "        print(f\"Classification Report for {model_file}:\\n\")\n",
        "        print(report)\n",
        "        print(\"\\n\" + \"=\" * 80 + \"\\n\")\n",
        "\n",
        "def plot_classification_metrics(results):\n",
        "    \"\"\"Plot precision, recall, and F1-score for all models with percentages on bars.\"\"\"\n",
        "    metrics = ['precision', 'recall', 'f1-score']\n",
        "    for model_file, data in results.items():\n",
        "        # Generate classification report as a dictionary\n",
        "        report = classification_report(\n",
        "            data[\"labels\"], data[\"preds\"], target_names=class_names, output_dict=True\n",
        "        )\n",
        "\n",
        "        # Extract metrics for each class (excluding 'accuracy' and 'macro avg')\n",
        "        class_metrics = {metric: [] for metric in metrics}\n",
        "        for class_name in class_names:\n",
        "            for metric in metrics:\n",
        "                class_metrics[metric].append(report[class_name][metric])\n",
        "\n",
        "        # Convert class names to a numpy array to avoid Seaborn warnings\n",
        "        class_array = np.array(class_names)\n",
        "\n",
        "        # Plot metrics for the current model\n",
        "        fig, axes = plt.subplots(1, 3, figsize=(18, 6), dpi=150)\n",
        "        for ax, metric in zip(axes, metrics):\n",
        "            # Create barplot\n",
        "            sns.barplot(y=class_array, x=class_metrics[metric], ax=ax, palette=\"viridis\")\n",
        "            ax.set_title(f\"{metric.capitalize()} by Class for {model_file}\")\n",
        "            ax.set_xlabel(metric.capitalize())\n",
        "            ax.set_ylabel(\"Class\")\n",
        "            ax.set_xlim(0, 1)  # Scores are between 0 and 1\n",
        "\n",
        "            # Add percentage labels inside bars\n",
        "            for i, value in enumerate(class_metrics[metric]):\n",
        "                ax.text(\n",
        "                    value + 0.02, i, f\"{value:.2%}\", va=\"center\", ha=\"left\", fontsize=9\n",
        "                )\n",
        "\n",
        "        plt.tight_layout()\n",
        "        # Save each model's figure with a different name\n",
        "        plt.savefig(f\"classification_metrics_{model_file}.png\", dpi=300, bbox_inches=\"tight\", format=\"png\")\n",
        "        plt.show()\n",
        "\n",
        "def plot_model_accuracies(results):\n",
        "    \"\"\"Plot overall accuracy for all models.\"\"\"\n",
        "    accuracies = {}\n",
        "    for model_file, data in results.items():\n",
        "        # Generate classification report as a dictionary\n",
        "        report = classification_report(\n",
        "            data[\"labels\"], data[\"preds\"], target_names=class_names, output_dict=True\n",
        "        )\n",
        "        # Extract overall accuracy\n",
        "        accuracies[model_file] = report['accuracy']\n",
        "\n",
        "    # Convert model names to a numpy array to avoid warnings\n",
        "    model_names = np.array(list(accuracies.keys()))\n",
        "    accuracy_values = list(accuracies.values())\n",
        "\n",
        "    plt.figure(figsize=(10, 6), dpi=150)\n",
        "    sns.barplot(x=accuracy_values, y=model_names, palette=\"viridis\")\n",
        "    plt.title(\"Overall Accuracy by Model\")\n",
        "    plt.xlabel(\"Accuracy\")\n",
        "    plt.ylabel(\"Model\")\n",
        "    plt.xlim(0, 1)  # Accuracy is between 0 and 1\n",
        "\n",
        "    # Add percentage labels inside bars\n",
        "    for i, value in enumerate(accuracy_values):\n",
        "        plt.text(\n",
        "            value + 0.02, i, f\"{value:.2%}\", va=\"center\", ha=\"left\", fontsize=10\n",
        "        )\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"model_accuracies.png\", dpi=300, bbox_inches=\"tight\", format=\"png\")\n",
        "    plt.show()\n",
        "\n",
        "# Evaluation and plotting for custom CNN\n",
        "num_classes = len(class_names)\n",
        "results = evaluate_custom_cnn_models(models_path, test_loader, num_classes)\n",
        "plot_confusion_matrices(results)\n",
        "plot_classification_reports(results)\n",
        "plot_classification_metrics(results)\n",
        "plot_model_accuracies(results)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-03T19:15:37.080647Z",
          "iopub.execute_input": "2025-02-03T19:15:37.080930Z",
          "iopub.status.idle": "2025-02-03T19:15:45.919824Z",
          "shell.execute_reply.started": "2025-02-03T19:15:37.080906Z",
          "shell.execute_reply": "2025-02-03T19:15:45.918643Z"
        },
        "id": "hWDHMX41JQws"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, num_classes=9):\n",
        "        super(CNNModel, self).__init__()\n",
        "\n",
        "        # Blocco convoluzionale base\n",
        "        self.conv_block1 = self._create_conv_block(3, 64)  # 64 filtri\n",
        "        self.conv_block2 = self._create_conv_block(64, 128)  # 128 filtri\n",
        "        self.conv_block3 = self._create_conv_block(128, 256)  # 256 filtri\n",
        "        self.conv_block4 = self._create_conv_block(256, 512)  # 512 filtri\n",
        "        self.conv_block5 = self._create_conv_block(512, 512)  # 512 filtri aggiuntivi\n",
        "\n",
        "        # Global Average Pooling\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        # Strati completamente connessi\n",
        "        self.fc1 = nn.Linear(512, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def _create_conv_block(self, in_channels, out_channels):\n",
        "        \"\"\"Crea un blocco convoluzionale standard.\"\"\"\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_block1(x)\n",
        "        x = self.conv_block2(x)\n",
        "        x = self.conv_block3(x)\n",
        "        x = self.conv_block4(x)\n",
        "        x = self.conv_block5(x)\n",
        "\n",
        "        # Global Average Pooling\n",
        "        x = self.global_avg_pool(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "\n",
        "        # Strati densi\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "def load_model(model_path, device):\n",
        "    \"\"\"\n",
        "    Load the model from the specified path and ensure it's ready for evaluation.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(model_path):\n",
        "        raise FileNotFoundError(f\"Model path '{model_path}' does not exist.\")\n",
        "\n",
        "    # Check if the model file ends with '.pth'\n",
        "    model_files = [f for f in os.listdir(model_path) if f.endswith('.pth')]\n",
        "    if not model_files:\n",
        "        raise FileNotFoundError(\"No model files ending with '.pth' found in the directory.\")\n",
        "\n",
        "    model_file_path = os.path.join(model_path, model_files[0])\n",
        "    print(f\"Loading model from {model_file_path}\")\n",
        "\n",
        "    # Load the state dict\n",
        "    model = torch.load(model_file_path, map_location=device)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "def evaluate_model(model, test_loader, device):\n",
        "    \"\"\"\n",
        "    Evaluate the model and collect predictions and labels.\n",
        "    \"\"\"\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (images, labels) in enumerate(test_loader):\n",
        "            # Ensure that images and labels are not empty\n",
        "            if images.shape[0] == 0:\n",
        "                print(f\"Warning: Empty batch at index {batch_idx}\")\n",
        "                continue\n",
        "\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            # Collect predictions and labels\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    if not all_preds or not all_labels:\n",
        "        print(\"Evaluation produced no predictions or labels.\")\n",
        "        return None\n",
        "\n",
        "    print(f\"Collected {len(all_preds)} predictions and {len(all_labels)} labels.\")\n",
        "    return np.array(all_preds), np.array(all_labels)\n",
        "\n",
        "# Example Execution\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define test data path and transformation\n",
        "test_data_path = \"/kaggle/input/last-test/test\"  # Update with your actual test dataset path\n",
        "\n",
        "# Define test transformations\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Adjust size as needed\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the test dataset\n",
        "try:\n",
        "    test_dataset = datasets.ImageFolder(root=test_data_path, transform=test_transforms)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "    print(f\"Loaded test dataset with {len(test_dataset)} images.\")\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error loading test dataset: {e}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-03T19:28:52.803483Z",
          "iopub.execute_input": "2025-02-03T19:28:52.803919Z",
          "iopub.status.idle": "2025-02-03T19:28:52.825905Z",
          "shell.execute_reply.started": "2025-02-03T19:28:52.803878Z",
          "shell.execute_reply": "2025-02-03T19:28:52.825089Z"
        },
        "id": "M7Saq2NDJQwt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms, datasets\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Define CNN Model\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, num_classes=9):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv_block1 = self._create_conv_block(3, 64)\n",
        "        self.conv_block2 = self._create_conv_block(64, 128)\n",
        "        self.conv_block3 = self._create_conv_block(128, 256)\n",
        "        self.conv_block4 = self._create_conv_block(256, 512)\n",
        "        self.conv_block5 = self._create_conv_block(512, 512)\n",
        "\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc1 = nn.Linear(512, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def _create_conv_block(self, in_channels, out_channels):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_block1(x)\n",
        "        x = self.conv_block2(x)\n",
        "        x = self.conv_block3(x)\n",
        "        x = self.conv_block4(x)\n",
        "        x = self.conv_block5(x)\n",
        "        x = self.global_avg_pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Function to load the model\n",
        "def load_model(model_path, device):\n",
        "    model = CNNModel()  # Instantiate the CNNModel class\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.to(device)\n",
        "    return model\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(model, dataloader, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    return all_preds, all_labels\n",
        "\n",
        "# Plot confusion matrix\n",
        "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.show()\n",
        "\n",
        "# Plot classification report\n",
        "def plot_classification_report(y_true, y_pred, class_names):\n",
        "    report = classification_report(y_true, y_pred, target_names=class_names)\n",
        "    print(\"Classification Report:\\n\", report)\n",
        "\n",
        "# Load and preprocess test dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_dataset_path = \"/kaggle/input/last-test/test\"  # Update with your test dataset path\n",
        "test_dataset = datasets.ImageFolder(root=test_dataset_path, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Load the model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_path = \"/kaggle/working/trained_Custom CNN_model.pth\"  # Replace with your correct model path\n",
        "\n",
        "try:\n",
        "    model = load_model(model_path, device)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Model file not found at {model_path}. Please check the path and file name.\")\n",
        "\n",
        "# Evaluate and plot results if model loading succeeds\n",
        "if 'model' in locals():\n",
        "    predictions, labels = evaluate_model(model, test_loader, device)\n",
        "\n",
        "    # Plot the confusion matrix and classification report\n",
        "    class_names = test_dataset.classes\n",
        "    plot_confusion_matrix(labels, predictions, class_names)\n",
        "    plot_classification_report(labels, predictions, class_names)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-03T19:31:11.398676Z",
          "iopub.execute_input": "2025-02-03T19:31:11.398969Z",
          "iopub.status.idle": "2025-02-03T19:31:12.575316Z",
          "shell.execute_reply.started": "2025-02-03T19:31:11.398944Z",
          "shell.execute_reply": "2025-02-03T19:31:12.574445Z"
        },
        "id": "Zrg41ZbXJQwu"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}