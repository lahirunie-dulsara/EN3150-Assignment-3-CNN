{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13385463,"sourceType":"datasetVersion","datasetId":8493277}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[],"gpuType":"T4","include_colab_link":true},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, models, transforms\nfrom torch.utils.data import DataLoader\nimport os\nimport shutil\nfrom sklearn.model_selection import train_test_split\nimport time","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T16:49:07.718204Z","iopub.execute_input":"2025-10-26T16:49:07.718945Z","iopub.status.idle":"2025-10-26T16:49:14.627211Z","shell.execute_reply.started":"2025-10-26T16:49:07.718918Z","shell.execute_reply":"2025-10-26T16:49:14.626573Z"},"id":"MZoPEPYVJQwY"},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Device configuration\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T16:49:15.739169Z","iopub.execute_input":"2025-10-26T16:49:15.739872Z","iopub.status.idle":"2025-10-26T16:49:15.802322Z","shell.execute_reply.started":"2025-10-26T16:49:15.739847Z","shell.execute_reply":"2025-10-26T16:49:15.801448Z"},"id":"JNUl-v37JQwc"},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"base_dir = \"/kaggle/input/realwaste/realwaste-main/RealWaste\"\nfor folder in os.listdir(base_dir):\n    count = len(os.listdir(os.path.join(base_dir, folder)))\n    print(f\"{folder}: {count} images\")","metadata":{"id":"eurMme0qObLX","trusted":true,"execution":{"iopub.status.busy":"2025-10-26T16:49:16.948210Z","iopub.execute_input":"2025-10-26T16:49:16.948893Z","iopub.status.idle":"2025-10-26T16:49:17.075390Z","shell.execute_reply.started":"2025-10-26T16:49:16.948867Z","shell.execute_reply":"2025-10-26T16:49:17.074605Z"}},"outputs":[{"name":"stdout","text":"Metal: 790 images\nGlass: 420 images\nPaper: 500 images\nVegetation: 436 images\nCardboard: 461 images\nTextile Trash: 318 images\nFood Organics: 411 images\nPlastic: 921 images\nMiscellaneous Trash: 495 images\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import os\nimport cv2\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nimport random\nimport numpy as np\nimport torch\nimport time\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom collections import Counter, defaultdict\n\n# Configuration\nBATCH_SIZE = 64\nIMG_SIZE = (224, 224)\nDATA_DIR = \"/kaggle/input/realwaste/realwaste-main/RealWaste\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T17:27:54.399137Z","iopub.execute_input":"2025-10-26T17:27:54.399846Z","iopub.status.idle":"2025-10-26T17:27:54.875495Z","shell.execute_reply.started":"2025-10-26T17:27:54.399820Z","shell.execute_reply":"2025-10-26T17:27:54.874738Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"pip install split-folders","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T16:58:43.168444Z","iopub.execute_input":"2025-10-26T16:58:43.169123Z","iopub.status.idle":"2025-10-26T16:58:47.414802Z","shell.execute_reply.started":"2025-10-26T16:58:43.169099Z","shell.execute_reply":"2025-10-26T16:58:47.414005Z"}},"outputs":[{"name":"stdout","text":"Collecting split-folders\n  Downloading split_folders-0.5.1-py3-none-any.whl.metadata (6.2 kB)\nDownloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\nInstalling collected packages: split-folders\nSuccessfully installed split-folders-0.5.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import splitfolders  # install with: pip install split-folders\n\ninput_folder = base_dir\nsplit_dir = \"/kaggle/working/RealWaste_split\"\n\nsplitfolders.ratio(input_folder, output=split_dir, seed=42, ratio=(.7, .15, .15))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T16:59:24.569257Z","iopub.execute_input":"2025-10-26T16:59:24.569820Z","iopub.status.idle":"2025-10-26T17:00:45.270370Z","shell.execute_reply.started":"2025-10-26T16:59:24.569798Z","shell.execute_reply":"2025-10-26T17:00:45.269745Z"}},"outputs":[{"name":"stderr","text":"\nCopying files: 0 files [00:00, ? files/s]\u001b[A\nCopying files: 1 files [00:01,  1.98s/ files]\u001b[A\nCopying files: 83 files [00:02, 55.61 files/s]\u001b[A\nCopying files: 162 files [00:02, 119.90 files/s]\u001b[A\nCopying files: 239 files [00:02, 192.03 files/s]\u001b[A\nCopying files: 319 files [00:02, 275.11 files/s]\u001b[A\nCopying files: 398 files [00:02, 359.16 files/s]\u001b[A\nCopying files: 478 files [00:02, 442.07 files/s]\u001b[A\nCopying files: 560 files [00:02, 521.55 files/s]\u001b[A\nCopying files: 643 files [00:02, 592.08 files/s]\u001b[A\nCopying files: 723 files [00:02, 629.97 files/s]\u001b[A\nCopying files: 801 files [00:04, 161.12 files/s]\u001b[A\nCopying files: 857 files [00:04, 174.99 files/s]\u001b[A\nCopying files: 903 files [00:04, 172.94 files/s]\u001b[A\nCopying files: 941 files [00:04, 174.27 files/s]\u001b[A\nCopying files: 979 files [00:05, 198.32 files/s]\u001b[A\nCopying files: 1058 files [00:05, 282.91 files/s]\u001b[A\nCopying files: 1137 files [00:05, 368.64 files/s]\u001b[A\nCopying files: 1211 files [00:06, 130.45 files/s]\u001b[A\nCopying files: 1252 files [00:06, 135.98 files/s]\u001b[A\nCopying files: 1286 files [00:07, 140.79 files/s]\u001b[A\nCopying files: 1315 files [00:07, 144.75 files/s]\u001b[A\nCopying files: 1340 files [00:07, 149.93 files/s]\u001b[A\nCopying files: 1363 files [00:07, 153.33 files/s]\u001b[A\nCopying files: 1384 files [00:07, 151.06 files/s]\u001b[A\nCopying files: 1403 files [00:08, 97.58 files/s] \u001b[A\nCopying files: 1418 files [00:08, 69.81 files/s]\u001b[A\nCopying files: 1433 files [00:08, 78.84 files/s]\u001b[A\nCopying files: 1451 files [00:08, 92.85 files/s]\u001b[A\nCopying files: 1469 files [00:08, 107.18 files/s]\u001b[A\nCopying files: 1486 files [00:08, 118.13 files/s]\u001b[A\nCopying files: 1502 files [00:09, 126.91 files/s]\u001b[A\nCopying files: 1520 files [00:09, 138.11 files/s]\u001b[A\nCopying files: 1538 files [00:09, 147.05 files/s]\u001b[A\nCopying files: 1555 files [00:09, 152.59 files/s]\u001b[A\nCopying files: 1572 files [00:09, 154.22 files/s]\u001b[A\nCopying files: 1589 files [00:09, 155.88 files/s]\u001b[A\nCopying files: 1607 files [00:09, 160.72 files/s]\u001b[A\nCopying files: 1624 files [00:10, 72.01 files/s] \u001b[A\nCopying files: 1637 files [00:10, 64.93 files/s]\u001b[A\nCopying files: 1654 files [00:10, 79.97 files/s]\u001b[A\nCopying files: 1673 files [00:10, 98.21 files/s]\u001b[A\nCopying files: 1689 files [00:10, 109.77 files/s]\u001b[A\nCopying files: 1706 files [00:10, 122.47 files/s]\u001b[A\nCopying files: 1722 files [00:12, 26.30 files/s] \u001b[A\nCopying files: 1736 files [00:12, 33.36 files/s]\u001b[A\nCopying files: 1748 files [00:12, 40.32 files/s]\u001b[A\nCopying files: 1760 files [00:12, 48.56 files/s]\u001b[A\nCopying files: 1772 files [00:13, 56.81 files/s]\u001b[A\nCopying files: 1784 files [00:13, 66.35 files/s]\u001b[A\nCopying files: 1796 files [00:13, 75.61 files/s]\u001b[A\nCopying files: 1808 files [00:13, 71.22 files/s]\u001b[A\nCopying files: 1818 files [00:13, 47.32 files/s]\u001b[A\nCopying files: 1826 files [00:14, 43.99 files/s]\u001b[A\nCopying files: 1840 files [00:14, 57.77 files/s]\u001b[A\nCopying files: 1853 files [00:14, 70.27 files/s]\u001b[A\nCopying files: 1866 files [00:14, 81.75 files/s]\u001b[A\nCopying files: 1878 files [00:14, 89.77 files/s]\u001b[A\nCopying files: 1890 files [00:14, 95.77 files/s]\u001b[A\nCopying files: 1902 files [00:14, 101.20 files/s]\u001b[A\nCopying files: 1914 files [00:14, 105.82 files/s]\u001b[A\nCopying files: 1927 files [00:14, 111.09 files/s]\u001b[A\nCopying files: 1939 files [00:15, 112.93 files/s]\u001b[A\nCopying files: 1951 files [00:15, 70.11 files/s] \u001b[A\nCopying files: 1961 files [00:15, 48.05 files/s]\u001b[A\nCopying files: 1969 files [00:15, 48.75 files/s]\u001b[A\nCopying files: 1979 files [00:16, 57.25 files/s]\u001b[A\nCopying files: 1991 files [00:16, 68.99 files/s]\u001b[A\nCopying files: 2003 files [00:16, 78.76 files/s]\u001b[A\nCopying files: 2015 files [00:16, 86.49 files/s]\u001b[A\nCopying files: 2027 files [00:16, 93.83 files/s]\u001b[A\nCopying files: 2039 files [00:16, 99.18 files/s]\u001b[A\nCopying files: 2051 files [00:16, 104.12 files/s]\u001b[A\nCopying files: 2063 files [00:16, 104.19 files/s]\u001b[A\nCopying files: 2074 files [00:16, 102.79 files/s]\u001b[A\nCopying files: 2085 files [00:17, 104.25 files/s]\u001b[A\nCopying files: 2098 files [00:17, 109.40 files/s]\u001b[A\nCopying files: 2110 files [00:17, 111.28 files/s]\u001b[A\nCopying files: 2123 files [00:17, 113.79 files/s]\u001b[A\nCopying files: 2135 files [00:17, 83.50 files/s] \u001b[A\nCopying files: 2145 files [00:17, 52.34 files/s]\u001b[A\nCopying files: 2153 files [00:19, 19.25 files/s]\u001b[A\nCopying files: 2173 files [00:19, 32.36 files/s]\u001b[A\nCopying files: 2189 files [00:19, 44.14 files/s]\u001b[A\nCopying files: 2201 files [00:19, 49.98 files/s]\u001b[A\nCopying files: 2212 files [00:19, 48.62 files/s]\u001b[A\nCopying files: 2221 files [00:20, 50.46 files/s]\u001b[A\nCopying files: 2229 files [00:20, 41.37 files/s]\u001b[A\nCopying files: 2241 files [00:20, 52.30 files/s]\u001b[A\nCopying files: 2260 files [00:20, 74.96 files/s]\u001b[A\nCopying files: 2276 files [00:20, 90.71 files/s]\u001b[A\nCopying files: 2293 files [00:20, 107.30 files/s]\u001b[A\nCopying files: 2311 files [00:20, 123.11 files/s]\u001b[A\nCopying files: 2328 files [00:20, 134.40 files/s]\u001b[A\nCopying files: 2345 files [00:21, 142.85 files/s]\u001b[A\nCopying files: 2363 files [00:21, 150.29 files/s]\u001b[A\nCopying files: 2381 files [00:21, 157.23 files/s]\u001b[A\nCopying files: 2398 files [00:21, 159.90 files/s]\u001b[A\nCopying files: 2415 files [00:21, 160.38 files/s]\u001b[A\nCopying files: 2433 files [00:21, 164.58 files/s]\u001b[A\nCopying files: 2450 files [00:21, 164.28 files/s]\u001b[A\nCopying files: 2467 files [00:21, 150.13 files/s]\u001b[A\nCopying files: 2483 files [00:22, 65.63 files/s] \u001b[A\nCopying files: 2495 files [00:22, 61.66 files/s]\u001b[A\nCopying files: 2510 files [00:22, 73.99 files/s]\u001b[A\nCopying files: 2526 files [00:22, 87.98 files/s]\u001b[A\nCopying files: 2541 files [00:22, 99.28 files/s]\u001b[A\nCopying files: 2554 files [00:23, 105.84 files/s]\u001b[A\nCopying files: 2567 files [00:23, 76.77 files/s] \u001b[A\nCopying files: 2578 files [00:23, 58.13 files/s]\u001b[A\nCopying files: 2587 files [00:23, 55.79 files/s]\u001b[A\nCopying files: 2598 files [00:23, 63.93 files/s]\u001b[A\nCopying files: 2607 files [00:24, 47.00 files/s]\u001b[A\nCopying files: 2614 files [00:26, 13.79 files/s]\u001b[A\nCopying files: 2619 files [00:26, 14.85 files/s]\u001b[A\nCopying files: 2623 files [00:26, 16.62 files/s]\u001b[A\nCopying files: 2628 files [00:26, 19.12 files/s]\u001b[A\nCopying files: 2632 files [00:26, 20.92 files/s]\u001b[A\nCopying files: 2637 files [00:26, 24.44 files/s]\u001b[A\nCopying files: 2642 files [00:26, 27.09 files/s]\u001b[A\nCopying files: 2647 files [00:27, 30.60 files/s]\u001b[A\nCopying files: 2653 files [00:27, 35.70 files/s]\u001b[A\nCopying files: 2658 files [00:27, 35.17 files/s]\u001b[A\nCopying files: 2663 files [00:27, 28.96 files/s]\u001b[A\nCopying files: 2668 files [00:27, 31.60 files/s]\u001b[A\nCopying files: 2673 files [00:27, 33.34 files/s]\u001b[A\nCopying files: 2678 files [00:27, 34.78 files/s]\u001b[A\nCopying files: 2682 files [00:28, 33.18 files/s]\u001b[A\nCopying files: 2686 files [00:28, 32.38 files/s]\u001b[A\nCopying files: 2690 files [00:28, 30.81 files/s]\u001b[A\nCopying files: 2705 files [00:28, 57.62 files/s]\u001b[A\nCopying files: 2720 files [00:28, 80.30 files/s]\u001b[A\nCopying files: 2733 files [00:28, 88.27 files/s]\u001b[A\nCopying files: 2743 files [00:29, 51.78 files/s]\u001b[A\nCopying files: 2751 files [00:29, 42.69 files/s]\u001b[A\nCopying files: 2759 files [00:29, 48.45 files/s]\u001b[A\nCopying files: 2766 files [00:29, 46.26 files/s]\u001b[A\nCopying files: 2772 files [00:29, 43.25 files/s]\u001b[A\nCopying files: 2778 files [00:29, 41.89 files/s]\u001b[A\nCopying files: 2783 files [00:30, 38.48 files/s]\u001b[A\nCopying files: 2788 files [00:30, 36.39 files/s]\u001b[A\nCopying files: 2792 files [00:30, 36.21 files/s]\u001b[A\nCopying files: 2796 files [00:30, 36.70 files/s]\u001b[A\nCopying files: 2800 files [00:30, 37.30 files/s]\u001b[A\nCopying files: 2804 files [00:30, 33.20 files/s]\u001b[A\nCopying files: 2808 files [00:30, 33.19 files/s]\u001b[A\nCopying files: 2812 files [00:31, 32.81 files/s]\u001b[A\nCopying files: 2821 files [00:31, 46.42 files/s]\u001b[A\nCopying files: 2835 files [00:31, 70.56 files/s]\u001b[A\nCopying files: 2844 files [00:31, 69.13 files/s]\u001b[A\nCopying files: 2852 files [00:31, 51.45 files/s]\u001b[A\nCopying files: 2859 files [00:31, 46.22 files/s]\u001b[A\nCopying files: 2865 files [00:31, 44.72 files/s]\u001b[A\nCopying files: 2870 files [00:32, 43.75 files/s]\u001b[A\nCopying files: 2881 files [00:32, 57.88 files/s]\u001b[A\nCopying files: 2888 files [00:32, 54.81 files/s]\u001b[A\nCopying files: 2894 files [00:32, 42.91 files/s]\u001b[A\nCopying files: 2899 files [00:32, 39.39 files/s]\u001b[A\nCopying files: 2904 files [00:32, 37.34 files/s]\u001b[A\nCopying files: 2909 files [00:33, 33.23 files/s]\u001b[A\nCopying files: 2920 files [00:33, 47.63 files/s]\u001b[A\nCopying files: 2926 files [00:35,  8.12 files/s]\u001b[A\nCopying files: 2938 files [00:35, 13.39 files/s]\u001b[A\nCopying files: 2944 files [00:36, 15.15 files/s]\u001b[A\nCopying files: 2949 files [00:36, 16.92 files/s]\u001b[A\nCopying files: 2954 files [00:36, 18.50 files/s]\u001b[A\nCopying files: 2958 files [00:36, 19.53 files/s]\u001b[A\nCopying files: 2965 files [00:36, 25.93 files/s]\u001b[A\nCopying files: 2978 files [00:36, 42.01 files/s]\u001b[A\nCopying files: 2992 files [00:36, 59.30 files/s]\u001b[A\nCopying files: 3004 files [00:36, 68.60 files/s]\u001b[A\nCopying files: 3017 files [00:37, 81.29 files/s]\u001b[A\nCopying files: 3031 files [00:37, 93.92 files/s]\u001b[A\nCopying files: 3043 files [00:37, 85.16 files/s]\u001b[A\nCopying files: 3053 files [00:37, 61.99 files/s]\u001b[A\nCopying files: 3061 files [00:37, 51.10 files/s]\u001b[A\nCopying files: 3073 files [00:37, 62.79 files/s]\u001b[A\nCopying files: 3082 files [00:38, 61.06 files/s]\u001b[A\nCopying files: 3090 files [00:38, 45.82 files/s]\u001b[A\nCopying files: 3096 files [00:38, 42.67 files/s]\u001b[A\nCopying files: 3102 files [00:38, 39.31 files/s]\u001b[A\nCopying files: 3109 files [00:38, 43.89 files/s]\u001b[A\nCopying files: 3115 files [00:39, 37.08 files/s]\u001b[A\nCopying files: 3120 files [00:39, 33.79 files/s]\u001b[A\nCopying files: 3129 files [00:39, 43.85 files/s]\u001b[A\nCopying files: 3141 files [00:39, 59.04 files/s]\u001b[A\nCopying files: 3149 files [00:39, 40.43 files/s]\u001b[A\nCopying files: 3155 files [00:40, 33.14 files/s]\u001b[A\nCopying files: 3160 files [00:40, 31.42 files/s]\u001b[A\nCopying files: 3172 files [00:40, 45.36 files/s]\u001b[A\nCopying files: 3180 files [00:40, 46.20 files/s]\u001b[A\nCopying files: 3186 files [00:40, 36.74 files/s]\u001b[A\nCopying files: 3191 files [00:41, 34.82 files/s]\u001b[A\nCopying files: 3196 files [00:41, 33.10 files/s]\u001b[A\nCopying files: 3206 files [00:41, 44.86 files/s]\u001b[A\nCopying files: 3218 files [00:41, 60.23 files/s]\u001b[A\nCopying files: 3230 files [00:41, 73.08 files/s]\u001b[A\nCopying files: 3239 files [00:41, 64.09 files/s]\u001b[A\nCopying files: 3247 files [00:42, 47.15 files/s]\u001b[A\nCopying files: 3254 files [00:42, 38.14 files/s]\u001b[A\nCopying files: 3266 files [00:42, 51.16 files/s]\u001b[A\nCopying files: 3278 files [00:42, 63.60 files/s]\u001b[A\nCopying files: 3287 files [00:42, 55.01 files/s]\u001b[A\nCopying files: 3295 files [00:43, 40.87 files/s]\u001b[A\nCopying files: 3301 files [00:43, 38.39 files/s]\u001b[A\nCopying files: 3308 files [00:43, 43.57 files/s]\u001b[A\nCopying files: 3320 files [00:43, 57.29 files/s]\u001b[A\nCopying files: 3331 files [00:43, 68.26 files/s]\u001b[A\nCopying files: 3340 files [00:51,  3.73 files/s]\u001b[A\nCopying files: 3350 files [00:51,  5.32 files/s]\u001b[A\nCopying files: 3357 files [00:52,  6.61 files/s]\u001b[A\nCopying files: 3363 files [00:52,  8.02 files/s]\u001b[A\nCopying files: 3368 files [00:52,  9.53 files/s]\u001b[A\nCopying files: 3373 files [00:52, 11.46 files/s]\u001b[A\nCopying files: 3378 files [00:52, 13.67 files/s]\u001b[A\nCopying files: 3389 files [00:52, 22.13 files/s]\u001b[A\nCopying files: 3402 files [00:52, 34.05 files/s]\u001b[A\nCopying files: 3411 files [00:53, 38.02 files/s]\u001b[A\nCopying files: 3419 files [00:53, 34.03 files/s]\u001b[A\nCopying files: 3425 files [00:53, 34.11 files/s]\u001b[A\nCopying files: 3431 files [00:53, 34.42 files/s]\u001b[A\nCopying files: 3443 files [00:53, 48.32 files/s]\u001b[A\nCopying files: 3457 files [00:54, 65.18 files/s]\u001b[A\nCopying files: 3466 files [00:54, 63.26 files/s]\u001b[A\nCopying files: 3474 files [00:54, 40.58 files/s]\u001b[A\nCopying files: 3481 files [00:54, 41.58 files/s]\u001b[A\nCopying files: 3487 files [00:54, 38.38 files/s]\u001b[A\nCopying files: 3492 files [00:55, 40.24 files/s]\u001b[A\nCopying files: 3504 files [00:55, 55.15 files/s]\u001b[A\nCopying files: 3511 files [00:55, 45.76 files/s]\u001b[A\nCopying files: 3517 files [00:55, 38.84 files/s]\u001b[A\nCopying files: 3522 files [00:55, 37.57 files/s]\u001b[A\nCopying files: 3527 files [00:55, 35.11 files/s]\u001b[A\nCopying files: 3532 files [00:56, 37.46 files/s]\u001b[A\nCopying files: 3538 files [00:56, 40.56 files/s]\u001b[A\nCopying files: 3543 files [00:56, 37.77 files/s]\u001b[A\nCopying files: 3548 files [00:56, 37.79 files/s]\u001b[A\nCopying files: 3554 files [00:56, 41.91 files/s]\u001b[A\nCopying files: 3559 files [00:56, 36.26 files/s]\u001b[A\nCopying files: 3563 files [00:56, 36.16 files/s]\u001b[A\nCopying files: 3572 files [00:56, 48.43 files/s]\u001b[A\nCopying files: 3584 files [00:57, 65.83 files/s]\u001b[A\nCopying files: 3598 files [00:57, 84.76 files/s]\u001b[A\nCopying files: 3608 files [00:57, 70.30 files/s]\u001b[A\nCopying files: 3616 files [00:57, 49.97 files/s]\u001b[A\nCopying files: 3623 files [00:57, 47.27 files/s]\u001b[A\nCopying files: 3629 files [00:58, 34.77 files/s]\u001b[A\nCopying files: 3634 files [00:58, 35.25 files/s]\u001b[A\nCopying files: 3645 files [00:58, 48.32 files/s]\u001b[A\nCopying files: 3659 files [00:58, 66.66 files/s]\u001b[A\nCopying files: 3674 files [00:58, 83.80 files/s]\u001b[A\nCopying files: 3685 files [00:58, 63.20 files/s]\u001b[A\nCopying files: 3694 files [00:59, 53.09 files/s]\u001b[A\nCopying files: 3701 files [00:59, 48.81 files/s]\u001b[A\nCopying files: 3707 files [00:59, 45.53 files/s]\u001b[A\nCopying files: 3720 files [00:59, 61.32 files/s]\u001b[A\nCopying files: 3734 files [00:59, 77.57 files/s]\u001b[A\nCopying files: 3744 files [00:59, 57.43 files/s]\u001b[A\nCopying files: 3752 files [01:00, 48.82 files/s]\u001b[A\nCopying files: 3759 files [01:00, 43.94 files/s]\u001b[A\nCopying files: 3770 files [01:00, 54.85 files/s]\u001b[A\nCopying files: 3783 files [01:00, 69.18 files/s]\u001b[A\nCopying files: 3793 files [01:00, 72.25 files/s]\u001b[A\nCopying files: 3802 files [01:01, 40.56 files/s]\u001b[A\nCopying files: 3809 files [01:01, 36.96 files/s]\u001b[A\nCopying files: 3815 files [01:01, 37.74 files/s]\u001b[A\nCopying files: 3828 files [01:01, 50.27 files/s]\u001b[A\nCopying files: 3835 files [01:01, 44.19 files/s]\u001b[A\nCopying files: 3841 files [01:02, 37.78 files/s]\u001b[A\nCopying files: 3846 files [01:02, 35.52 files/s]\u001b[A\nCopying files: 3853 files [01:02, 41.30 files/s]\u001b[A\nCopying files: 3863 files [01:02, 52.46 files/s]\u001b[A\nCopying files: 3870 files [01:02, 54.92 files/s]\u001b[A\nCopying files: 3877 files [01:02, 42.84 files/s]\u001b[A\nCopying files: 3883 files [01:03, 38.46 files/s]\u001b[A\nCopying files: 3888 files [01:03, 35.13 files/s]\u001b[A\nCopying files: 3896 files [01:03, 43.65 files/s]\u001b[A\nCopying files: 3907 files [01:03, 57.63 files/s]\u001b[A\nCopying files: 3921 files [01:03, 76.21 files/s]\u001b[A\nCopying files: 3930 files [01:03, 64.44 files/s]\u001b[A\nCopying files: 3938 files [01:04, 56.85 files/s]\u001b[A\nCopying files: 3945 files [01:04, 46.83 files/s]\u001b[A\nCopying files: 3951 files [01:04, 40.60 files/s]\u001b[A\nCopying files: 3961 files [01:04, 51.33 files/s]\u001b[A\nCopying files: 3973 files [01:04, 65.15 files/s]\u001b[A\nCopying files: 3981 files [01:04, 58.42 files/s]\u001b[A\nCopying files: 3988 files [01:05, 47.12 files/s]\u001b[A\nCopying files: 3994 files [01:05, 27.78 files/s]\u001b[A\nCopying files: 4005 files [01:05, 38.68 files/s]\u001b[A\nCopying files: 4017 files [01:05, 51.62 files/s]\u001b[A\nCopying files: 4025 files [01:06, 39.38 files/s]\u001b[A\nCopying files: 4032 files [01:06, 36.79 files/s]\u001b[A\nCopying files: 4038 files [01:06, 36.13 files/s]\u001b[A\nCopying files: 4051 files [01:06, 51.45 files/s]\u001b[A\nCopying files: 4066 files [01:06, 70.08 files/s]\u001b[A\nCopying files: 4076 files [01:06, 63.90 files/s]\u001b[A\nCopying files: 4085 files [01:07, 49.76 files/s]\u001b[A\nCopying files: 4092 files [01:07, 38.36 files/s]\u001b[A\nCopying files: 4100 files [01:07, 44.55 files/s]\u001b[A\nCopying files: 4114 files [01:07, 61.45 files/s]\u001b[A\nCopying files: 4128 files [01:07, 77.23 files/s]\u001b[A\nCopying files: 4141 files [01:07, 88.76 files/s]\u001b[A\nCopying files: 4156 files [01:08, 103.43 files/s]\u001b[A\nCopying files: 4169 files [01:08, 68.71 files/s] \u001b[A\nCopying files: 4179 files [01:08, 51.80 files/s]\u001b[A\nCopying files: 4187 files [01:08, 50.44 files/s]\u001b[A\nCopying files: 4201 files [01:08, 64.91 files/s]\u001b[A\nCopying files: 4216 files [01:09, 79.75 files/s]\u001b[A\nCopying files: 4230 files [01:09, 91.97 files/s]\u001b[A\nCopying files: 4244 files [01:09, 102.56 files/s]\u001b[A\nCopying files: 4256 files [01:09, 53.04 files/s] \u001b[A\nCopying files: 4266 files [01:12, 13.50 files/s]\u001b[A\nCopying files: 4273 files [01:12, 15.39 files/s]\u001b[A\nCopying files: 4279 files [01:12, 17.85 files/s]\u001b[A\nCopying files: 4290 files [01:12, 24.85 files/s]\u001b[A\nCopying files: 4306 files [01:12, 38.15 files/s]\u001b[A\nCopying files: 4320 files [01:12, 49.92 files/s]\u001b[A\nCopying files: 4331 files [01:13, 41.57 files/s]\u001b[A\nCopying files: 4340 files [01:13, 40.46 files/s]\u001b[A\nCopying files: 4347 files [01:13, 39.58 files/s]\u001b[A\nCopying files: 4361 files [01:13, 54.20 files/s]\u001b[A\nCopying files: 4377 files [01:13, 72.48 files/s]\u001b[A\nCopying files: 4392 files [01:13, 87.46 files/s]\u001b[A\nCopying files: 4404 files [01:14, 62.64 files/s]\u001b[A\nCopying files: 4414 files [01:14, 51.52 files/s]\u001b[A\nCopying files: 4422 files [01:14, 48.79 files/s]\u001b[A\nCopying files: 4435 files [01:14, 61.50 files/s]\u001b[A\nCopying files: 4448 files [01:15, 73.40 files/s]\u001b[A\nCopying files: 4463 files [01:15, 89.32 files/s]\u001b[A\nCopying files: 4475 files [01:15, 63.14 files/s]\u001b[A\nCopying files: 4484 files [01:15, 50.41 files/s]\u001b[A\nCopying files: 4492 files [01:15, 51.60 files/s]\u001b[A\nCopying files: 4506 files [01:15, 66.62 files/s]\u001b[A\nCopying files: 4519 files [01:16, 78.82 files/s]\u001b[A\nCopying files: 4534 files [01:16, 92.91 files/s]\u001b[A\nCopying files: 4546 files [01:16, 87.30 files/s]\u001b[A\nCopying files: 4557 files [01:16, 54.51 files/s]\u001b[A\nCopying files: 4565 files [01:17, 41.86 files/s]\u001b[A\nCopying files: 4572 files [01:17, 38.90 files/s]\u001b[A\nCopying files: 4582 files [01:17, 47.56 files/s]\u001b[A\nCopying files: 4589 files [01:17, 38.94 files/s]\u001b[A\nCopying files: 4595 files [01:17, 33.58 files/s]\u001b[A\nCopying files: 4600 files [01:18, 32.79 files/s]\u001b[A\nCopying files: 4604 files [01:18, 31.74 files/s]\u001b[A\nCopying files: 4615 files [01:18, 45.22 files/s]\u001b[A\nCopying files: 4623 files [01:18, 48.11 files/s]\u001b[A\nCopying files: 4629 files [01:18, 42.21 files/s]\u001b[A\nCopying files: 4634 files [01:18, 37.09 files/s]\u001b[A\nCopying files: 4639 files [01:19, 34.95 files/s]\u001b[A\nCopying files: 4643 files [01:19, 35.79 files/s]\u001b[A\nCopying files: 4656 files [01:19, 55.89 files/s]\u001b[A\nCopying files: 4670 files [01:19, 75.73 files/s]\u001b[A\nCopying files: 4684 files [01:19, 91.38 files/s]\u001b[A\nCopying files: 4695 files [01:19, 81.15 files/s]\u001b[A\nCopying files: 4705 files [01:20, 50.92 files/s]\u001b[A\nCopying files: 4713 files [01:20, 43.80 files/s]\u001b[A\nCopying files: 4719 files [01:20, 46.25 files/s]\u001b[A\nCopying files: 4733 files [01:20, 62.72 files/s]\u001b[A\nCopying files: 4752 files [01:20, 58.90 files/s]\u001b[A\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Count images in each subfolder\nfor split in ['train', 'val', 'test']:\n    split_path = os.path.join(split_dir, split)\n    print(f\"\\n{split.upper()} SET\")\n    total = 0\n    for cls in os.listdir(split_path):\n        cls_path = os.path.join(split_path, cls)\n        count = len(os.listdir(cls_path))\n\n        total += count\n        print(f\"  {cls}: {count} images\")\n    print(f\" Total {split}: {total} images\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T17:01:19.659150Z","iopub.execute_input":"2025-10-26T17:01:19.659836Z","iopub.status.idle":"2025-10-26T17:01:19.668721Z","shell.execute_reply.started":"2025-10-26T17:01:19.659811Z","shell.execute_reply":"2025-10-26T17:01:19.667920Z"}},"outputs":[{"name":"stdout","text":"\nTRAIN SET\n  Glass: 294 images\n  Food Organics: 287 images\n  Metal: 553 images\n  Miscellaneous Trash: 346 images\n  Plastic: 644 images\n  Cardboard: 322 images\n  Textile Trash: 222 images\n  Paper: 350 images\n  Vegetation: 305 images\n Total train: 3323 images\n\nVAL SET\n  Glass: 63 images\n  Food Organics: 61 images\n  Metal: 118 images\n  Miscellaneous Trash: 74 images\n  Plastic: 138 images\n  Cardboard: 69 images\n  Textile Trash: 47 images\n  Paper: 75 images\n  Vegetation: 65 images\n Total val: 710 images\n\nTEST SET\n  Glass: 63 images\n  Food Organics: 63 images\n  Metal: 119 images\n  Miscellaneous Trash: 75 images\n  Plastic: 139 images\n  Cardboard: 70 images\n  Textile Trash: 49 images\n  Paper: 75 images\n  Vegetation: 66 images\n Total test: 719 images\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import os\nimport torch\nfrom torch.utils.data import DataLoader, WeightedRandomSampler\nfrom torchvision import datasets, transforms\nimport numpy as np # Already imported later, but useful here\nfrom tqdm import tqdm # For progress bars\n\n\ntrain_transforms = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=45),\n        transforms.RandomResizedCrop(size=IMG_SIZE[0], scale=(0.6, 0.9)),\n        transforms.Resize(IMG_SIZE),\n        transforms.ToTensor()\n])\n\nval_test_transforms = transforms.Compose([\n    transforms.Resize(IMG_SIZE),\n    transforms.ToTensor(),\n])\n\ntrain_dataset = datasets.ImageFolder(\"/kaggle/working/RealWaste_split/train\", transform=train_transforms)\nval_dataset   = datasets.ImageFolder(\"/kaggle/working/RealWaste_split/val\", transform=val_test_transforms)\ntest_dataset  = datasets.ImageFolder(\"/kaggle/working/RealWaste_split/test\", transform=val_test_transforms)\n\n# Get number of classes and device early\nnum_classes = len(train_dataset.classes)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\nprint(f\"Number of classes: {num_classes}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T17:29:00.368688Z","iopub.execute_input":"2025-10-26T17:29:00.369461Z","iopub.status.idle":"2025-10-26T17:29:00.388649Z","shell.execute_reply.started":"2025-10-26T17:29:00.369428Z","shell.execute_reply":"2025-10-26T17:29:00.388065Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nNumber of classes: 9\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"from torch.utils.data import ConcatDataset\n\nduplication_factor = 3\ntrain_dataset_augmented = ConcatDataset([train_dataset] * duplication_factor)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T17:37:17.983683Z","iopub.execute_input":"2025-10-26T17:37:17.984415Z","iopub.status.idle":"2025-10-26T17:37:17.987859Z","shell.execute_reply.started":"2025-10-26T17:37:17.984388Z","shell.execute_reply":"2025-10-26T17:37:17.987172Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# Assuming train_dataset, val_dataset, test_dataset are defined from Block 1\n\n# Extract targets manually\ntargets = []\nfor dataset in train_dataset_augmented.datasets:  # ConcatDataset.datasets is a list\n    if hasattr(dataset, 'targets'):\n        targets.extend(dataset.targets)\n    else:\n        # fallback if custom dataset\n        for i in range(len(dataset)):\n            _, label = dataset[i]\n            targets.append(label)\n\n# Convert to numpy\nimport numpy as np\ntargets = np.array(targets)\n\n# Class counts\nclass_counts = np.bincount(targets)\nprint(\"Class counts:\", class_counts)\n\nbase_dataset = train_dataset_augmented.datasets[0]  # first dataset in the concat list\nclasses = base_dataset.classes\n\n# Compute class weights (inverse of frequency)\nclass_weights_tensor = 1. / torch.tensor(class_counts, dtype=torch.float)\n\n# Ensure sample_weights are floats for the sampler\nsample_weights = [class_weights_tensor[label].item() for label in targets]\n\nprint(\"Class counts per category:\")\nfor cls, count in zip(classes, class_counts):\n    print(f\"  {cls:15s}: {count}\")\n\nprint(\"\\n Class weights (inverse of frequency):\")\nfor cls, w in zip(classes, class_weights_tensor):\n    print(f\"  {cls:15s}: {w:.6f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T17:43:18.209570Z","iopub.execute_input":"2025-10-26T17:43:18.210158Z","iopub.status.idle":"2025-10-26T17:43:18.246060Z","shell.execute_reply.started":"2025-10-26T17:43:18.210136Z","shell.execute_reply":"2025-10-26T17:43:18.245310Z"}},"outputs":[{"name":"stdout","text":"Class counts: [ 966  861  882 1659 1038 1050 1932  666  915]\nClass counts per category:\n  Cardboard      : 966\n  Food Organics  : 861\n  Glass          : 882\n  Metal          : 1659\n  Miscellaneous Trash: 1038\n  Paper          : 1050\n  Plastic        : 1932\n  Textile Trash  : 666\n  Vegetation     : 915\n\n Class weights (inverse of frequency):\n  Cardboard      : 0.001035\n  Food Organics  : 0.001161\n  Glass          : 0.001134\n  Metal          : 0.000603\n  Miscellaneous Trash: 0.000963\n  Paper          : 0.000952\n  Plastic        : 0.000518\n  Textile Trash  : 0.001502\n  Vegetation     : 0.001093\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"# Define a consistent BATCH_SIZE\nBATCH_SIZE = 32 # Increased batch size\n\ntrain_loader = DataLoader(train_dataset_augmented, batch_size=BATCH_SIZE, shuffle=True) # ADDED: num_workers\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False) # ADDED: val_loader\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False) # ADDED: test_loader\n\n\nprint(f\"\\n WeightedRandomSampler created successfully!\")\nprint(f\" Total samples in epoch: {len(sample_weights)}\")\nprint(f\" Training Batch size: {train_loader.batch_size}\")\nprint(f\" Validation Batch size: {val_loader.batch_size}\")\nprint(f\" Total training batches per epoch: {len(train_loader)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T17:43:39.919504Z","iopub.execute_input":"2025-10-26T17:43:39.920064Z","iopub.status.idle":"2025-10-26T17:43:39.925493Z","shell.execute_reply.started":"2025-10-26T17:43:39.920029Z","shell.execute_reply":"2025-10-26T17:43:39.924726Z"}},"outputs":[{"name":"stdout","text":"\n WeightedRandomSampler created successfully!\n Total samples in epoch: 9969\n Training Batch size: 32\n Validation Batch size: 32\n Total training batches per epoch: 312\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n    train_losses, val_losses = [], []\n    train_accuracies, val_accuracies = [], []\n\n    for epoch in range(num_epochs):\n        # ======== TRAINING ========\n        model.train()\n        running_loss = 0.0\n        correct_train = 0\n        total_train = 0\n\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item() * images.size(0)\n            _, predicted = torch.max(outputs, 1)\n            total_train += labels.size(0)\n            correct_train += (predicted == labels).sum().item()\n\n        epoch_train_loss = running_loss / len(train_loader.dataset)\n        epoch_train_acc = 100 * correct_train / total_train\n        train_losses.append(epoch_train_loss)\n        train_accuracies.append(epoch_train_acc)\n\n        # ======== VALIDATION ========\n        model.eval()\n        val_loss_total = 0.0\n        correct_val = 0\n        total_val = 0\n\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n\n                val_loss_total += loss.item() * images.size(0)\n                _, predicted = torch.max(outputs, 1)\n                total_val += labels.size(0)\n                correct_val += (predicted == labels).sum().item()\n\n        epoch_val_loss = val_loss_total / len(val_loader.dataset)\n        epoch_val_acc = 100 * correct_val / total_val\n        val_losses.append(epoch_val_loss)\n        val_accuracies.append(epoch_val_acc)\n\n        print(f\"Epoch {epoch+1}/{num_epochs}: \"\n              f\"Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.2f}%, \"\n              f\"Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_val_acc:.2f}%\")\n\n    return train_losses, val_losses, train_accuracies, val_accuracies\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T18:20:45.609671Z","iopub.execute_input":"2025-10-26T18:20:45.610197Z","iopub.status.idle":"2025-10-26T18:20:45.618607Z","shell.execute_reply.started":"2025-10-26T18:20:45.610173Z","shell.execute_reply":"2025-10-26T18:20:45.617817Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"class CNNModel(nn.Module):\n    def __init__(self, num_classes=9):\n        super(CNNModel, self).__init__()\n\n        # Blocco convoluzionale base\n        self.conv_block1 = self._create_conv_block(3, 64)  # 64 filtri\n        self.conv_block2 = self._create_conv_block(64, 128)  # 128 filtri\n        self.conv_block3 = self._create_conv_block(128, 256)  # 256 filtri\n        self.conv_block4 = self._create_conv_block(256, 512)  # 512 filtri\n        self.conv_block5 = self._create_conv_block(512, 512)  # 512 filtri aggiuntivi\n\n        # Global Average Pooling\n        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n\n        # Strati completamente connessi\n        self.fc1 = nn.Linear(512, 512)\n        self.fc2 = nn.Linear(512, num_classes)\n        self.dropout = nn.Dropout(0.3)\n\n    def _create_conv_block(self, in_channels, out_channels):\n        return nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n\n    def forward(self, x):\n        x = self.conv_block1(x)\n        x = self.conv_block2(x)\n        x = self.conv_block3(x)\n        x = self.conv_block4(x)\n        x = self.conv_block5(x)\n\n        # Global Average Pooling\n        x = self.global_avg_pool(x)\n        x = x.view(x.size(0), -1)  # Flatten\n\n        # Strati densi\n        x = nn.functional.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\n\n        return x\n# Istanza del modello\nmodel = CNNModel(num_classes=9)\n\nmodel_name = \"Custom CNN\"\n\n# Configurazione del dispositivo\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Conversione dei pesi al dispositivo\nweights = torch.tensor(class_weights.copy(), dtype=torch.float32).to(device)  # Personalizza i pesi\ncriterion = nn.CrossEntropyLoss(weight=weights)\n\n# Modello sul dispositivo\nmodel = model.to(device)\n\n# Ottimizzatore\nlearning_rate = 1e-5\nweight_decay = 1e-2\noptimizer = optim.Adam(\n    filter(lambda p: p.requires_grad, model.parameters()),\n    lr=learning_rate,\n    weight_decay=weight_decay\n)\n\n# Scheduler del learning rate\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n\n# Numero di epoche\nnum_epochs = 20\n\n# Training del modello\ntrain_losses, val_losses, train_accuracies, val_accuracies = train_model(\n    model=model,\n    train_loader=train_loader,\n    val_loader=val_loader,\n    criterion=criterion,\n    optimizer=optimizer,\n    num_epochs=num_epochs\n)\n\n# Plot delle metriche di training e validazione\nplot_training_validation_metrics(\n    train_losses=train_losses,\n    val_losses=val_losses,\n    train_accuracies=train_accuracies,\n    val_accuracies=val_accuracies\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T18:21:43.054258Z","iopub.execute_input":"2025-10-26T18:21:43.054789Z"},"id":"O-w9CQXwJQwq"},"outputs":[{"name":"stdout","text":"Using device: cuda\nEpoch 1/20: Train Loss: 1.5532, Train Acc: 46.37%, Val Loss: 1.3023, Val Acc: 55.77%\nEpoch 2/20: Train Loss: 1.1399, Train Acc: 60.20%, Val Loss: 1.0935, Val Acc: 61.27%\nEpoch 3/20: Train Loss: 0.9598, Train Acc: 66.60%, Val Loss: 0.9461, Val Acc: 66.76%\nEpoch 4/20: Train Loss: 0.8635, Train Acc: 69.58%, Val Loss: 0.8761, Val Acc: 71.41%\nEpoch 5/20: Train Loss: 0.7945, Train Acc: 71.65%, Val Loss: 0.7934, Val Acc: 72.54%\nEpoch 6/20: Train Loss: 0.7255, Train Acc: 74.20%, Val Loss: 0.7646, Val Acc: 73.38%\nEpoch 7/20: Train Loss: 0.6803, Train Acc: 75.65%, Val Loss: 0.7058, Val Acc: 74.37%\nEpoch 8/20: Train Loss: 0.6291, Train Acc: 77.19%, Val Loss: 0.7353, Val Acc: 73.24%\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# Save the model\nmodel_save_path = f\"/kaggle/working/trained_{model_name}_model.pth\"\ntorch.save(model.state_dict(), model_save_path)\nprint(f\"Model saved to {model_save_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T19:15:08.777556Z","iopub.execute_input":"2025-02-03T19:15:08.777883Z","iopub.status.idle":"2025-02-03T19:15:08.875795Z","shell.execute_reply.started":"2025-02-03T19:15:08.777856Z","shell.execute_reply":"2025-02-03T19:15:08.875000Z"},"id":"gL6mDTAVJQwr"},"outputs":[],"execution_count":null}]}