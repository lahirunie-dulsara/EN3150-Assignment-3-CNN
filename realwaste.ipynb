{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"colab":{"gpuType":"T4","include_colab_link":true,"provenance":[]},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13507342,"sourceType":"datasetVersion","datasetId":8576031}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!cd /kaggle/working/\n!rm -rf *","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T16:42:36.981343Z","iopub.execute_input":"2025-10-27T16:42:36.981749Z","iopub.status.idle":"2025-10-27T16:42:37.216492Z","shell.execute_reply.started":"2025-10-27T16:42:36.981717Z","shell.execute_reply":"2025-10-27T16:42:37.215509Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip install split-folders","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T16:42:37.218146Z","iopub.execute_input":"2025-10-27T16:42:37.218376Z","iopub.status.idle":"2025-10-27T16:42:41.847298Z","shell.execute_reply.started":"2025-10-27T16:42:37.218357Z","shell.execute_reply":"2025-10-27T16:42:41.846569Z"}},"outputs":[{"name":"stdout","text":"Collecting split-folders\n  Downloading split_folders-0.5.1-py3-none-any.whl.metadata (6.2 kB)\nDownloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\nInstalling collected packages: split-folders\nSuccessfully installed split-folders-0.5.1\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import StepLR\nfrom torchvision import datasets, models, transforms\nimport os\nimport shutil\nimport time\nimport cv2\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler, ConcatDataset\nfrom PIL import Image\nimport random\nimport numpy as np\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom collections import Counter, defaultdict\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport splitfolders","metadata":{"execution":{"iopub.status.busy":"2025-10-27T16:42:41.848331Z","iopub.execute_input":"2025-10-27T16:42:41.848601Z","iopub.status.idle":"2025-10-27T16:42:50.987316Z","shell.execute_reply.started":"2025-10-27T16:42:41.848580Z","shell.execute_reply":"2025-10-27T16:42:50.986559Z"},"id":"MZoPEPYVJQwY","trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Device configuration\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"execution":{"iopub.status.busy":"2025-10-27T16:42:50.988812Z","iopub.execute_input":"2025-10-27T16:42:50.989120Z","iopub.status.idle":"2025-10-27T16:42:51.065343Z","shell.execute_reply.started":"2025-10-27T16:42:50.989104Z","shell.execute_reply":"2025-10-27T16:42:51.064558Z"},"id":"JNUl-v37JQwc","trusted":true},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"input_path = \"/kaggle/input/realwaste-dataset/realwaste-main/RealWaste\"\n\nworking_path = \"/kaggle/working/realwaste\"\n\nshutil.copytree(input_path, working_path, dirs_exist_ok=True)\n\nprint(\"Dataset copied successfully to working directory!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T16:42:51.066164Z","iopub.execute_input":"2025-10-27T16:42:51.066453Z","iopub.status.idle":"2025-10-27T16:43:29.105576Z","shell.execute_reply.started":"2025-10-27T16:42:51.066430Z","shell.execute_reply":"2025-10-27T16:43:29.104591Z"}},"outputs":[{"name":"stdout","text":"Dataset copied successfully to working directory!\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"base_dir = \"/kaggle/working/realwaste\"\nfor folder in os.listdir(base_dir):\n    count = len(os.listdir(os.path.join(base_dir, folder)))\n    print(f\"{folder}: {count} images\")","metadata":{"execution":{"iopub.status.busy":"2025-10-27T16:43:29.106542Z","iopub.execute_input":"2025-10-27T16:43:29.106812Z","iopub.status.idle":"2025-10-27T16:43:29.114425Z","shell.execute_reply.started":"2025-10-27T16:43:29.106781Z","shell.execute_reply":"2025-10-27T16:43:29.113785Z"},"id":"eurMme0qObLX","trusted":true},"outputs":[{"name":"stdout","text":"Miscellaneous Trash: 495 images\nFood Organics: 411 images\nPlastic: 921 images\nCardboard: 461 images\nTextile Trash: 318 images\nGlass: 420 images\nVegetation: 436 images\nPaper: 500 images\nMetal: 790 images\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Configuration\nIMG_SIZE = (224, 224)\nDATA_DIR = \"/kaggle/input/realwaste/realwaste-main/RealWaste\"","metadata":{"execution":{"iopub.status.busy":"2025-10-27T16:43:29.115185Z","iopub.execute_input":"2025-10-27T16:43:29.115436Z","iopub.status.idle":"2025-10-27T16:43:29.134453Z","shell.execute_reply.started":"2025-10-27T16:43:29.115398Z","shell.execute_reply":"2025-10-27T16:43:29.133857Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"input_folder = base_dir\nsplit_dir = \"/kaggle/working/RealWaste_split\"\n\nsplitfolders.ratio(input_folder, output=split_dir, seed=42, ratio=(.7, .15, .15))","metadata":{"execution":{"iopub.status.busy":"2025-10-27T16:43:29.135220Z","iopub.execute_input":"2025-10-27T16:43:29.135452Z","iopub.status.idle":"2025-10-27T16:43:30.227360Z","shell.execute_reply.started":"2025-10-27T16:43:29.135435Z","shell.execute_reply":"2025-10-27T16:43:30.226632Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Copying files: 4752 files [00:01, 4415.63 files/s]\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Count images in each subfolder\nfor split in ['train', 'val', 'test']:\n    split_path = os.path.join(split_dir, split)\n    print(f\"\\n{split.upper()} SET\")\n    total = 0\n    for cls in os.listdir(split_path):\n        cls_path = os.path.join(split_path, cls)\n        count = len(os.listdir(cls_path))\n\n        total += count\n        print(f\"  {cls}: {count} images\")\n    print(f\" Total {split}: {total} images\")","metadata":{"execution":{"iopub.status.busy":"2025-10-27T16:43:30.228066Z","iopub.execute_input":"2025-10-27T16:43:30.228240Z","iopub.status.idle":"2025-10-27T16:43:30.236811Z","shell.execute_reply.started":"2025-10-27T16:43:30.228226Z","shell.execute_reply":"2025-10-27T16:43:30.236282Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\nTRAIN SET\n  Miscellaneous Trash: 346 images\n  Food Organics: 287 images\n  Plastic: 644 images\n  Cardboard: 322 images\n  Textile Trash: 222 images\n  Glass: 294 images\n  Vegetation: 305 images\n  Paper: 350 images\n  Metal: 553 images\n Total train: 3323 images\n\nVAL SET\n  Miscellaneous Trash: 74 images\n  Food Organics: 61 images\n  Plastic: 138 images\n  Cardboard: 69 images\n  Textile Trash: 47 images\n  Glass: 63 images\n  Vegetation: 65 images\n  Paper: 75 images\n  Metal: 118 images\n Total val: 710 images\n\nTEST SET\n  Miscellaneous Trash: 75 images\n  Food Organics: 63 images\n  Plastic: 139 images\n  Cardboard: 70 images\n  Textile Trash: 49 images\n  Glass: 63 images\n  Vegetation: 66 images\n  Paper: 75 images\n  Metal: 119 images\n Total test: 719 images\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Data Augmentation\ntrain_transforms = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=45),\n        transforms.RandomResizedCrop(size=IMG_SIZE[0], scale=(0.6, 0.9)),\n        transforms.Resize(IMG_SIZE),\n        transforms.ToTensor()\n])\n\nval_test_transforms = transforms.Compose([\n    transforms.Resize(IMG_SIZE),\n    transforms.ToTensor(),\n])\n\ntrain_dataset = datasets.ImageFolder(\"/kaggle/working/RealWaste_split/train\", transform=train_transforms)\nval_dataset   = datasets.ImageFolder(\"/kaggle/working/RealWaste_split/val\", transform=val_test_transforms)\ntest_dataset  = datasets.ImageFolder(\"/kaggle/working/RealWaste_split/test\", transform=val_test_transforms)\n\n# Get number of classes and device\nnum_classes = len(train_dataset.classes)\nprint(f\"Number of classes: {num_classes}\")","metadata":{"execution":{"iopub.status.busy":"2025-10-27T16:43:30.239170Z","iopub.execute_input":"2025-10-27T16:43:30.239636Z","iopub.status.idle":"2025-10-27T16:43:30.260883Z","shell.execute_reply.started":"2025-10-27T16:43:30.239619Z","shell.execute_reply":"2025-10-27T16:43:30.260183Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Number of classes: 9\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Increase the number of training data\nduplication_factor = 3\ntrain_dataset_augmented = ConcatDataset([train_dataset] * duplication_factor)","metadata":{"execution":{"iopub.status.busy":"2025-10-27T16:43:30.261763Z","iopub.execute_input":"2025-10-27T16:43:30.262005Z","iopub.status.idle":"2025-10-27T16:43:30.265779Z","shell.execute_reply.started":"2025-10-27T16:43:30.261990Z","shell.execute_reply":"2025-10-27T16:43:30.265029Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Extract targets\ntargets = []\nfor dataset in train_dataset_augmented.datasets:  # train_dataset_augmented.datasets is a list\n    if hasattr(dataset, 'targets'):\n        targets.extend(dataset.targets)\n    else:\n        # fallback if custom dataset\n        for i in range(len(dataset)):\n            _, label = dataset[i]\n            targets.append(label)\n\n# Convert to numpy\ntargets = np.array(targets)\n\n# Class counts\nclass_counts = np.bincount(targets)\nprint(\"Class counts:\", class_counts)\n\nbase_dataset = train_dataset_augmented.datasets[0]  # first dataset in the concat list\nclasses = base_dataset.classes\n\n# Compute class weights (inverse of frequency)\nclass_weights = 1. / class_counts\n\n# Ensure sample_weights are floats for the sampler\nsample_weights = [class_weights[label].item() for label in targets]\n\nprint(\"Class counts per category:\")\nfor cls, count in zip(classes, class_counts):\n    print(f\"  {cls:15s}: {count}\")\n\nprint(\"\\n Class weights (inverse of frequency):\")\nfor cls, w in zip(classes, class_weights):\n    print(f\"  {cls:15s}: {w:.6f}\")","metadata":{"execution":{"iopub.status.busy":"2025-10-27T16:43:30.266501Z","iopub.execute_input":"2025-10-27T16:43:30.266852Z","iopub.status.idle":"2025-10-27T16:43:30.287256Z","shell.execute_reply.started":"2025-10-27T16:43:30.266829Z","shell.execute_reply":"2025-10-27T16:43:30.286708Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Class counts: [ 966  861  882 1659 1038 1050 1932  666  915]\nClass counts per category:\n  Cardboard      : 966\n  Food Organics  : 861\n  Glass          : 882\n  Metal          : 1659\n  Miscellaneous Trash: 1038\n  Paper          : 1050\n  Plastic        : 1932\n  Textile Trash  : 666\n  Vegetation     : 915\n\n Class weights (inverse of frequency):\n  Cardboard      : 0.001035\n  Food Organics  : 0.001161\n  Glass          : 0.001134\n  Metal          : 0.000603\n  Miscellaneous Trash: 0.000963\n  Paper          : 0.000952\n  Plastic        : 0.000518\n  Textile Trash  : 0.001502\n  Vegetation     : 0.001093\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Define a consistent BATCH_SIZE\nBATCH_SIZE = 32\n\ntrain_loader = DataLoader(train_dataset_augmented, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False) \ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\n\nprint(f\"\\n WeightedRandomSampler created successfully!\")\nprint(f\" Total samples in epoch: {len(sample_weights)}\")\nprint(f\" Training Batch size: {train_loader.batch_size}\")\nprint(f\" Validation Batch size: {val_loader.batch_size}\")\nprint(f\" Total training batches per epoch: {len(train_loader)}\")","metadata":{"execution":{"iopub.status.busy":"2025-10-27T16:43:30.288188Z","iopub.execute_input":"2025-10-27T16:43:30.288712Z","iopub.status.idle":"2025-10-27T16:43:30.306501Z","shell.execute_reply.started":"2025-10-27T16:43:30.288687Z","shell.execute_reply":"2025-10-27T16:43:30.305792Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\n WeightedRandomSampler created successfully!\n Total samples in epoch: 9969\n Training Batch size: 32\n Validation Batch size: 32\n Total training batches per epoch: 312\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs):\n    train_losses, val_losses = [], []\n    train_accuracies, val_accuracies = [], []\n\n\n    for epoch in range(num_epochs):\n        model.train()\n        running_loss = 0\n        correct = 0\n        total = 0\n    \n        # TRAINING LOOP\n        train_loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} (Train)\", leave=False)\n        for images, labels in train_loop:\n            images, labels = images.to(device), labels.to(device)\n    \n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n    \n            running_loss += loss.item() * images.size(0)\n    \n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n            train_acc = 100 * correct / total\n            train_loop.set_postfix(loss=loss.item(), acc=train_acc)\n    \n        epoch_train_loss = running_loss / len(train_loader.dataset)\n        epoch_train_acc = 100 * correct / total\n\n        train_losses.append(epoch_train_loss)\n        train_accuracies.append(epoch_train_acc)\n\n        # VALIDATION LOOP\n        model.eval()\n        val_running_loss = 0\n        val_correct = 0\n        val_total = 0\n    \n        with torch.no_grad():\n            val_loop = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} (Val)\", leave=False)\n            for images, labels in val_loop:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n    \n                val_running_loss += loss.item() * images.size(0)\n    \n                _, predicted = torch.max(outputs, 1)\n                val_total += labels.size(0)\n                val_correct += (predicted == labels).sum().item()\n    \n        epoch_val_loss = val_running_loss / len(val_loader.dataset)\n        epoch_val_acc = 100 * val_correct / val_total\n\n        val_losses.append(epoch_val_loss)\n        val_accuracies.append(epoch_val_acc)\n        \n        # Summary\n        print(f\"Epoch {epoch+1}/{num_epochs}: \"\n              f\"Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.2f}% | \"\n              f\"Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_val_acc:.2f}%\")\n\n    return train_losses, val_losses, train_accuracies, val_accuracies","metadata":{"execution":{"iopub.status.busy":"2025-10-27T16:43:30.307166Z","iopub.execute_input":"2025-10-27T16:43:30.307384Z","iopub.status.idle":"2025-10-27T16:43:30.321059Z","shell.execute_reply.started":"2025-10-27T16:43:30.307362Z","shell.execute_reply":"2025-10-27T16:43:30.320467Z"},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"code","source":"class CNNModel(nn.Module):\n    def __init__(self, num_classes=9):\n        super(CNNModel, self).__init__()\n\n        # Convolution Blocks\n        self.conv_block1 = self._create_conv_block(3, 64)  # 64 filters\n        self.conv_block2 = self._create_conv_block(64, 128)  # 128 filters\n        self.conv_block3 = self._create_conv_block(128, 256)  # 256 filters\n        self.conv_block4 = self._create_conv_block(256, 512)  # 512 filters\n        self.conv_block5 = self._create_conv_block(512, 512)  # 512 filters\n        # Global Average Pooling\n        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n\n        # Fully Connected Layers\n        self.fc1 = nn.Linear(512, 512)\n        self.fc2 = nn.Linear(512, num_classes)\n        self.dropout = nn.Dropout(0.3)\n\n    def _create_conv_block(self, in_channels, out_channels):\n        return nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n\n    def forward(self, x):\n        x = self.conv_block1(x)\n        x = self.conv_block2(x)\n        x = self.conv_block3(x)\n        x = self.conv_block4(x)\n        x = self.conv_block5(x)\n\n        # Global Average Pooling\n        x = self.global_avg_pool(x)\n        x = x.view(x.size(0), -1)  # Flatten\n\n        x = nn.functional.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\n\n        return x\n\nmodel = CNNModel(num_classes=num_classes)\nmodel_name = \"Custom CNN\"\n\n# Loss Function\nweights = torch.tensor(class_weights.copy(), dtype=torch.float32).to(device)\ncriterion = nn.CrossEntropyLoss(weight=weights)\n\nmodel = model.to(device)\n\nresults = {}\n\ndef reset_weights(model):\n    for layer in model.children():\n        if hasattr(layer, 'reset_parameters'):\n            layer.reset_parameters()","metadata":{"execution":{"iopub.status.busy":"2025-10-27T16:43:30.321769Z","iopub.execute_input":"2025-10-27T16:43:30.321997Z","iopub.status.idle":"2025-10-27T16:43:30.637800Z","shell.execute_reply.started":"2025-10-27T16:43:30.321979Z","shell.execute_reply":"2025-10-27T16:43:30.637190Z"},"id":"O-w9CQXwJQwq","trusted":true},"outputs":[],"execution_count":15},{"cell_type":"code","source":"print(f\"\\n===== Training with Adam =====\\n\")\n\nreset_weights(model)\n\n# Adams Optimizer \nlearning_rate = 1e-5\nweight_decay = 1e-2\noptimizer = optim.Adam(\n    filter(lambda p: p.requires_grad, model.parameters()),\n    lr=learning_rate,\n    weight_decay=weight_decay\n)\n\n# Scheduler of learning rate\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n\nnum_epochs = 20\n\n# Training the model\ntrain_losses, val_losses, train_accuracies, val_accuracies = train_model(\n    model=model,\n    train_loader=train_loader,\n    val_loader=val_loader,\n    criterion=criterion,\n    optimizer=optimizer,\n    num_epochs=num_epochs\n)\n\n# Save the model\nresults['Adam'] = (train_losses, val_losses, train_accuracies, val_accuracies)\n\nmodel_save_path = f\"/kaggle/working/trained_{model_name}_adam.pth\"\ntorch.save(model.state_dict(), model_save_path)\nprint(f\"Model saved to {model_save_path}\")","metadata":{"execution":{"iopub.status.busy":"2025-10-27T16:43:30.638534Z","iopub.execute_input":"2025-10-27T16:43:30.638754Z","iopub.status.idle":"2025-10-27T17:29:23.822487Z","shell.execute_reply.started":"2025-10-27T16:43:30.638738Z","shell.execute_reply":"2025-10-27T17:29:23.821702Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\n===== Training with Adam =====\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20: Train Loss: 1.5036, Train Acc: 48.86% | Val Loss: 1.3147, Val Acc: 54.23%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2/20: Train Loss: 1.1043, Train Acc: 61.71% | Val Loss: 1.0890, Val Acc: 59.44%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3/20: Train Loss: 0.9315, Train Acc: 67.44% | Val Loss: 0.9674, Val Acc: 66.20%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4/20: Train Loss: 0.8444, Train Acc: 69.89% | Val Loss: 0.8754, Val Acc: 68.87%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5/20: Train Loss: 0.7622, Train Acc: 72.80% | Val Loss: 0.8198, Val Acc: 70.56%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6/20: Train Loss: 0.7108, Train Acc: 74.44% | Val Loss: 0.7713, Val Acc: 71.83%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7/20: Train Loss: 0.6472, Train Acc: 76.83% | Val Loss: 0.7576, Val Acc: 74.51%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8/20: Train Loss: 0.6132, Train Acc: 77.41% | Val Loss: 0.7083, Val Acc: 74.23%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9/20: Train Loss: 0.5752, Train Acc: 78.92% | Val Loss: 0.6434, Val Acc: 77.75%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10/20: Train Loss: 0.5312, Train Acc: 80.43% | Val Loss: 0.6580, Val Acc: 77.89%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 11/20: Train Loss: 0.5109, Train Acc: 81.12% | Val Loss: 0.6089, Val Acc: 78.87%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 12/20: Train Loss: 0.4813, Train Acc: 82.28% | Val Loss: 0.5677, Val Acc: 80.99%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 13/20: Train Loss: 0.4538, Train Acc: 83.41% | Val Loss: 0.5519, Val Acc: 79.86%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 14/20: Train Loss: 0.4225, Train Acc: 84.57% | Val Loss: 0.5230, Val Acc: 79.44%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 15/20: Train Loss: 0.4082, Train Acc: 85.52% | Val Loss: 0.5583, Val Acc: 80.42%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 16/20: Train Loss: 0.3914, Train Acc: 85.72% | Val Loss: 0.6076, Val Acc: 78.31%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 17/20: Train Loss: 0.3638, Train Acc: 86.57% | Val Loss: 0.5865, Val Acc: 78.73%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 18/20: Train Loss: 0.3688, Train Acc: 86.57% | Val Loss: 0.5542, Val Acc: 79.58%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 19/20: Train Loss: 0.3306, Train Acc: 88.14% | Val Loss: 0.5004, Val Acc: 83.10%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                            ","output_type":"stream"},{"name":"stdout","text":"Epoch 20/20: Train Loss: 0.3354, Train Acc: 87.80% | Val Loss: 0.5163, Val Acc: 81.55%\nModel saved to /kaggle/working/trained_Custom CNN_adam.pth\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"print(f\"\\n===== Training with SGD =====\\n\")\n\nreset_weights(model)\n\n# SGD Optimizer \nlearning_rate = 1e-3\nweight_decay = 1e-4\noptimizer = optim.SGD(\n    model.parameters(), \n    lr= learning_rate, \n    weight_decay= weight_decay\n)\n\n# Scheduler of learning rate\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n\nnum_epochs = 20\n\n# Training the model\ntrain_losses, val_losses, train_accuracies, val_accuracies = train_model(\n    model=model,\n    train_loader=train_loader,\n    val_loader=val_loader,\n    criterion=criterion,\n    optimizer=optimizer,\n    num_epochs=num_epochs\n)\n\n# Save the model\nresults['SGD'] = (train_losses, val_losses, train_accuracies, val_accuracies)\n\nmodel_save_path = f\"/kaggle/working/trained_{model_name}_sgd.pth\"\ntorch.save(model.state_dict(), model_save_path)\nprint(f\"Model saved to {model_save_path}\")","metadata":{"execution":{"iopub.status.busy":"2025-10-27T17:29:23.823328Z","iopub.execute_input":"2025-10-27T17:29:23.823573Z","execution_failed":"2025-10-27T18:01:37.213Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\n===== Training with SGD =====\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20: Train Loss: 1.4416, Train Acc: 67.45% | Val Loss: 1.1180, Val Acc: 69.15%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2/20: Train Loss: 0.8069, Train Acc: 81.43% | Val Loss: 1.1299, Val Acc: 58.45%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3/20: Train Loss: 0.6074, Train Acc: 83.86% | Val Loss: 1.2246, Val Acc: 54.79%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4/20: Train Loss: 0.5193, Train Acc: 84.75% | Val Loss: 0.8920, Val Acc: 68.03%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5/20: Train Loss: 0.4580, Train Acc: 86.36% | Val Loss: 0.6772, Val Acc: 78.31%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6/20: Train Loss: 0.4216, Train Acc: 86.23% | Val Loss: 0.7743, Val Acc: 73.10%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7/20: Train Loss: 0.3948, Train Acc: 87.37% | Val Loss: 0.5643, Val Acc: 79.15%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8/20: Train Loss: 0.3715, Train Acc: 87.63% | Val Loss: 0.5582, Val Acc: 80.00%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9/20: Train Loss: 0.3558, Train Acc: 88.03% | Val Loss: 1.0569, Val Acc: 67.46%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10/20: Train Loss: 0.3385, Train Acc: 88.38% | Val Loss: 1.0138, Val Acc: 64.51%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 11/20: Train Loss: 0.3084, Train Acc: 89.50% | Val Loss: 0.5920, Val Acc: 78.03%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 12/20: Train Loss: 0.3125, Train Acc: 88.94% | Val Loss: 1.4849, Val Acc: 57.61%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 13/20: Train Loss: 0.2939, Train Acc: 89.84% | Val Loss: 0.5879, Val Acc: 80.42%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 14/20: Train Loss: 0.2845, Train Acc: 89.98% | Val Loss: 0.8045, Val Acc: 71.41%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/20 (Train):   6%|▌         | 18/312 [00:07<02:02,  2.39it/s, acc=90.8, loss=0.211] ","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"print(f\"\\n===== Training with SGD with Momentum =====\\n\")\n\nreset_weights(model)\n\n# SGD with Momentum Optimizer \nlearning_rate = 1e-4\nweight_decay = 1e-4\noptimizer = optim.SGD(\n    model.parameters(), \n    lr= learning_rate, \n    weight_decay= weight_decay,\n    momentum=0.8\n)\n\n# Scheduler of learning rate\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n\nnum_epochs = 20\n\n# Training the model\ntrain_losses, val_losses, train_accuracies, val_accuracies = train_model(\n    model=model,\n    train_loader=train_loader,\n    val_loader=val_loader,\n    criterion=criterion,\n    optimizer=optimizer,\n    num_epochs=num_epochs\n)\n\n# Save the model\nresults['SGD with Momentum'] = (train_losses, val_losses, train_accuracies, val_accuracies)\n\nmodel_save_path = f\"/kaggle/working/trained_{model_name}_sgdmomentum.pth\"\ntorch.save(model.state_dict(), model_save_path)\nprint(f\"Model saved to {model_save_path}\")","metadata":{"execution":{"execution_failed":"2025-10-27T18:01:37.214Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(14, 10))\n\n# 1️ Train Loss\nplt.subplot(2, 2, 1)\nfor name in results:\n    plt.plot(results[name][0], label=f\"{name}\")\nplt.title(\"Training Loss per Epoch\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.grid(True)\n\n# 2️ Validation Loss\nplt.subplot(2, 2, 2)\nfor name in results:\n    plt.plot(results[name][1], label=f\"{name}\")\nplt.title(\"Validation Loss per Epoch\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.grid(True)\n\n# 3️ Training Accuracy\nplt.subplot(2, 2, 3)\nfor name in results:\n    plt.plot(results[name][2], label=f\"{name}\")\nplt.title(\"Training Accuracy per Epoch\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy (%)\")\nplt.legend()\nplt.grid(True)\n\n# 4️ Validation Accuracy\nplt.subplot(2, 2, 4)\nfor name in results:\n    plt.plot(results[name][3], label=f\"{name}\")\nplt.title(\"Validation Accuracy per Epoch\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy (%)\")\nplt.legend()\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"execution_failed":"2025-10-27T18:01:37.214Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\n===== Validation Accuracy Comparison =====\\n\")\nfor name in results:\n    val_acc_list = results[name][3]   \n    if len(val_acc_list) > 0:\n        final_val_acc = val_acc_list[-1]  \n        print(f\"{name} Final Validation Accuracy: {final_val_acc:.2f}%\")\n    else:\n        print(f\"{name} has no validation records. (Check training loop)\")\n\nprint(\"\\n===== Best Validation Accuracy for Each Optimizer =====\\n\")\nfor name in results:\n    val_acc_list = results[name][3]\n    if len(val_acc_list) > 0:\n        best_val_acc = max(val_acc_list)\n        print(f\"{name} Best Validation Accuracy: {best_val_acc:.2f}%\")\n    else:\n        print(f\"{name} has no validation records.\")","metadata":{"execution":{"execution_failed":"2025-10-27T18:01:37.214Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_model(model, test_loader, criterion):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            test_loss += loss.item() * images.size(0)\n\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    avg_test_loss = test_loss / len(test_loader.dataset)\n    test_accuracy = 100 * correct / total\n\n    return avg_test_loss, test_accuracy","metadata":{"execution":{"execution_failed":"2025-10-27T18:01:37.214Z"},"id":"gL6mDTAVJQwr","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_paths = {\n    \"Adam\": \"/kaggle/working/trained_Custom CNN_adam.pth\",\n    \"SGD\": \"/kaggle/working/trained_Custom CNN_sgd.pth\",\n    \"SGD with Momentum\": \"/kaggle/working/trained_Custom CNN_sgdmomentum.pth\"\n}\n\nprint(\"\\n===== Test Set Evaluation =====\\n\")\n\nfor name, path in model_paths.items():\n    # Load fresh model architecture\n    test_model = CNNModel(num_classes=9).to(device)\n    test_model.load_state_dict(torch.load(path, map_location=device))\n\n    test_loss, test_acc = evaluate_model(test_model, test_loader, criterion)\n\n    print(f\"{name} Optimizer -> Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}%\")\n","metadata":{"execution":{"execution_failed":"2025-10-27T18:01:37.214Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_detailed(model, loader, class_names):\n    model.eval()\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for images, labels in loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs, 1)\n\n            all_preds.extend(predicted.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    # Classification report\n    print(\"\\nClassification Report:\")\n    print(classification_report(all_labels, all_preds, target_names=class_names))\n\n    # Confusion matrix\n    cm = confusion_matrix(all_labels, all_preds)\n\n    plt.figure(figsize=(8,6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\",\n                xticklabels=classes, yticklabels=classes)\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"Actual\")\n    plt.title(\"Confusion Matrix\")\n    plt.show()\n","metadata":{"execution":{"execution_failed":"2025-10-27T18:01:37.214Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_paths = {\n    \"Adam\": \"/kaggle/working/trained_Custom CNN_adam.pth\",\n    \"SGD\": \"/kaggle/working/trained_Custom CNN_sgd.pth\",\n    \"SGD with Momentum\": \"/kaggle/working/trained_Custom CNN_sgdmomentum.pth\"\n}\n\nprint(\"\\n===== Detailed Test Evaluation for Each Optimizer =====\\n\")\n\nfor name, path in model_paths.items():\n    print(f\"\\n--- {name} Optimizer ---\\n\")\n\n    test_model = CNNModel(num_classes=9).to(device)\n    test_model.load_state_dict(torch.load(path, map_location=device))\n\n    evaluate_detailed(test_model, test_loader, classes)\n","metadata":{"execution":{"execution_failed":"2025-10-27T18:01:37.214Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Pre-trained Models","metadata":{}},{"cell_type":"code","source":"# Data Augmentation\n\ndata_transforms = {\n    \"train\": transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomRotation(15),\n        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406],\n                             [0.229, 0.224, 0.225])\n    ]),\n    \"val\": transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406],\n                             [0.229, 0.224, 0.225])\n    ]),\n}\n\nimage_datasets = {\n    x: datasets.ImageFolder(f\"{split_dir}/{x}\", data_transforms[x])\n    for x in [\"train\", \"val\"]\n}\ndataloaders = {\n    x: DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=2)\n    for x in [\"train\", \"val\"]\n}\ndataset_sizes = {x: len(image_datasets[x]) for x in [\"train\", \"val\"]}\nclass_names = image_datasets[\"train\"].classes","metadata":{"trusted":true,"execution":{"execution_failed":"2025-10-27T18:01:37.214Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training Function (with Early Stopping)\ndef train_model(model, criterion, optimizer, scheduler, num_epochs, patience=5):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    early_stop_counter = 0\n\n    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n\n    print(f\"\\n========== Training {model.__class__.__name__} ==========\\n\")\n\n    for epoch in range(num_epochs):\n        print(f\"Epoch {epoch+1}/{num_epochs}\\n\" + \"-\"*30)\n\n        # Each epoch has a training and validation phase\n        for phase in [\"train\", \"val\"]:\n            if phase == \"train\":\n                model.train()\n            else:\n                model.eval()\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data\n            for inputs, labels in dataloaders[phase]:\n                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n                optimizer.zero_grad()\n\n                with torch.set_grad_enabled(phase == \"train\"):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    if phase == \"train\":\n                        loss.backward()\n                        optimizer.step()\n\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            if phase == \"train\":\n                scheduler.step()\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n            if phase == \"train\":\n                train_losses.append(epoch_loss)\n                train_accs.append(epoch_acc.item())\n            else:\n                val_losses.append(epoch_loss)\n                val_accs.append(epoch_acc.item())\n\n            print(f\"{phase.capitalize()} Loss: {epoch_loss:.4f}, {phase.capitalize()} Acc: {epoch_acc:.4f}\")\n\n            # Early stopping based on validation accuracy\n            if phase == \"val\":\n                if epoch_acc > best_acc:\n                    best_acc = epoch_acc\n                    best_model_wts = copy.deepcopy(model.state_dict())\n                    early_stop_counter = 0\n                else:\n                    early_stop_counter += 1\n\n        print()\n        if early_stop_counter >= patience:\n            print(f\"Early stopping at epoch {epoch+1}\")\n            break\n\n    time_elapsed = time.time() - since\n    print(f\"Training complete in {time_elapsed//60:.0f}m {time_elapsed%60:.0f}s\")\n    print(f\"Best Val Acc: {best_acc:.4f}\")\n\n    model.load_state_dict(best_model_wts)\n    return model, train_losses, val_losses, train_accs, val_accs","metadata":{"trusted":true,"execution":{"execution_failed":"2025-10-27T18:01:37.214Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Model Definition Function\n\ndef get_model(model_name, num_classes, fine_tune=True, dropout_p=0.5):\n    if model_name == \"resnet\":\n        model = models.resnet18(pretrained=True)\n        if not fine_tune:\n            for param in model.parameters():\n                param.requires_grad = False\n        in_features = model.fc.in_features\n        model.fc = nn.Sequential(\n            nn.Dropout(dropout_p),\n            nn.Linear(in_features, num_classes)\n        )\n\n    elif model_name == \"vgg\":\n        model = models.vgg16(pretrained=True)\n        if not fine_tune:\n            for param in model.features.parameters():\n                param.requires_grad = False\n        in_features = model.classifier[6].in_features\n        model.classifier[6] = nn.Sequential(\n            nn.Dropout(dropout_p),\n            nn.Linear(in_features, num_classes)\n        )\n\n    return model.to(DEVICE)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-10-27T18:01:37.214Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"NUM_EPOCHS_COMP = 20 \ncriterion = nn.CrossEntropyLoss()\nLEARNING_RATE = 0.001\nnum_classes = len(class_names)\n\n# --- 1. ResNet-18 Transfer Learning ---\n\nmodel_resnet = get_model(\"resnet\", num_classes)\noptimizer_resnet = optim.Adam(model_resnet.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\nscheduler_resnet = StepLR(optimizer_resnet, step_size=10, gamma=0.1)\nmodel_resnet, resnet_train_loss, resnet_val_loss, resnet_train_acc, resnet_val_acc = train_model(\n    model_resnet, criterion, optimizer_resnet, scheduler_resnet, num_epochs=NUM_EPOCHS_COMP\n)\n\n# --- 2. VGG-16 Transfer Learning ---\n\nmodel_vgg = get_model(\"vgg\", num_classes)\noptimizer_vgg = optim.Adam(model_vgg.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\nscheduler_vgg = StepLR(optimizer_vgg, step_size=10, gamma=0.1)\nmodel_vgg, vgg_train_loss, vgg_val_loss, vgg_train_acc, vgg_val_acc = train_model(\n    model_vgg, criterion, optimizer_vgg, scheduler_vgg, num_epochs=NUM_EPOCHS_COMP\n)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-10-27T18:01:37.214Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plotting Functions\ndef plot_metrics(train_loss, val_loss, train_acc, val_acc, title):\n    epochs = range(1, len(train_loss) + 1)\n    plt.figure(figsize=(12, 5))\n\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, train_loss, label=\"Train Loss\")\n    plt.plot(epochs, val_loss, label=\"Val Loss\")\n    plt.title(f\"{title} - Loss\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, train_acc, label=\"Train Acc\")\n    plt.plot(epochs, val_acc, label=\"Val Acc\")\n    plt.title(f\"{title} - Accuracy\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Accuracy\")\n    plt.legend()\n    plt.show()\n\nplot_metrics(resnet_train_loss, resnet_val_loss, resnet_train_acc, resnet_val_acc, \"ResNet18\")\nplot_metrics(vgg_train_loss, vgg_val_loss, vgg_train_acc, vgg_val_acc, \"VGG16\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-10-27T18:01:37.214Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Test data transformations\ntest_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                         [0.229, 0.224, 0.225])\n])\n\n# Load test dataset\ntest_dataset = datasets.ImageFolder('/kaggle/working/realwaste_split/test', transform=test_transform)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-10-27T18:01:37.214Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#For ResNet18\nmodel_to_test = model_resnet  \nmodel_to_test.eval()          \nall_preds = []\nall_labels = []\n\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = model_to_test(inputs)\n        _, preds = torch.max(outputs, 1)\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\n# Calculate test accuracy\ntest_accuracy = np.mean(np.array(all_preds) == np.array(all_labels))\nprint(f\" Test Accuracy: {test_accuracy * 100:.2f}%\")\n\n# Confusion matrix\ncm = confusion_matrix(all_labels, all_preds)\nclass_names = test_dataset.classes\n\n#  Plot Confusion Matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=class_names, yticklabels=class_names)\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()\n\n# Classification Report\nprint(\"\\nClassification Report:\\n\")\nprint(classification_report(all_labels, all_preds, target_names=class_names))\n\n#  Overall Metrics\nprecision_macro = precision_score(all_labels, all_preds, average='macro')\nrecall_macro = recall_score(all_labels, all_preds, average='macro')\nf1_macro = f1_score(all_labels, all_preds, average='macro')\n\nprecision_weighted = precision_score(all_labels, all_preds, average='weighted')\nrecall_weighted = recall_score(all_labels, all_preds, average='weighted')\nf1_weighted = f1_score(all_labels, all_preds, average='weighted')\n\nprint(f\"\\n Overall Metrics:\")\nprint(f\"Macro Precision: {precision_macro:.4f}\")\nprint(f\"Macro Recall:    {recall_macro:.4f}\")\nprint(f\"Macro F1-Score:  {f1_macro:.4f}\")\nprint(f\"Weighted Precision: {precision_weighted:.4f}\")\nprint(f\"Weighted Recall:    {recall_weighted:.4f}\")\nprint(f\"Weighted F1-Score:  {f1_weighted:.4f}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-10-27T18:01:37.214Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#For VGG16\nmodel_to_test = model_vgg  \nmodel_to_test.eval()          \n\nall_preds = []\nall_labels = []\n\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = model_to_test(inputs)\n        _, preds = torch.max(outputs, 1)\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\n# Calculate test accuracy\ntest_accuracy = np.mean(np.array(all_preds) == np.array(all_labels))\nprint(f\" Test Accuracy: {test_accuracy * 100:.2f}%\")\n\n# Confusion matrix\ncm = confusion_matrix(all_labels, all_preds)\nclass_names = test_dataset.classes\n\n#  Plot Confusion Matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=class_names, yticklabels=class_names)\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()\n\n#  Classification Report\nprint(\"\\nClassification Report:\\n\")\nprint(classification_report(all_labels, all_preds, target_names=class_names))\n\n#  Overall Metrics\nprecision_macro = precision_score(all_labels, all_preds, average='macro')\nrecall_macro = recall_score(all_labels, all_preds, average='macro')\nf1_macro = f1_score(all_labels, all_preds, average='macro')\n\nprecision_weighted = precision_score(all_labels, all_preds, average='weighted')\nrecall_weighted = recall_score(all_labels, all_preds, average='weighted')\nf1_weighted = f1_score(all_labels, all_preds, average='weighted')\n\nprint(f\"\\n Overall Metrics:\")\nprint(f\"Macro Precision: {precision_macro:.4f}\")\nprint(f\"Macro Recall:    {recall_macro:.4f}\")\nprint(f\"Macro F1-Score:  {f1_macro:.4f}\")\nprint(f\"Weighted Precision: {precision_weighted:.4f}\")\nprint(f\"Weighted Recall:    {recall_weighted:.4f}\")\nprint(f\"Weighted F1-Score:  {f1_weighted:.4f}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-10-27T18:01:37.214Z"}},"outputs":[],"execution_count":null}]}